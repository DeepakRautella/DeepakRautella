{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275ec5f3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.155865Z",
     "iopub.status.busy": "2022-10-19T05:44:13.154392Z",
     "iopub.status.idle": "2022-10-19T05:44:13.175085Z",
     "shell.execute_reply": "2022-10-19T05:44:13.174037Z"
    },
    "papermill": {
     "duration": 0.036558,
     "end_time": "2022-10-19T05:44:13.178590",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.142032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bank-customers/Churn Modeling.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ea8d360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.197973Z",
     "iopub.status.busy": "2022-10-19T05:44:13.197495Z",
     "iopub.status.idle": "2022-10-19T05:44:13.249663Z",
     "shell.execute_reply": "2022-10-19T05:44:13.248224Z"
    },
    "papermill": {
     "duration": 0.064657,
     "end_time": "2022-10-19T05:44:13.252432",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.187775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/kaggle/input/bank-customers/Churn Modeling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a78e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.270170Z",
     "iopub.status.busy": "2022-10-19T05:44:13.269626Z",
     "iopub.status.idle": "2022-10-19T05:44:13.306733Z",
     "shell.execute_reply": "2022-10-19T05:44:13.305172Z"
    },
    "papermill": {
     "duration": 0.04905,
     "end_time": "2022-10-19T05:44:13.309342",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.260292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2848ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.327797Z",
     "iopub.status.busy": "2022-10-19T05:44:13.327309Z",
     "iopub.status.idle": "2022-10-19T05:44:13.334981Z",
     "shell.execute_reply": "2022-10-19T05:44:13.333789Z"
    },
    "papermill": {
     "duration": 0.019916,
     "end_time": "2022-10-19T05:44:13.337472",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.317556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2b2f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.356324Z",
     "iopub.status.busy": "2022-10-19T05:44:13.355775Z",
     "iopub.status.idle": "2022-10-19T05:44:13.389073Z",
     "shell.execute_reply": "2022-10-19T05:44:13.386467Z"
    },
    "papermill": {
     "duration": 0.046284,
     "end_time": "2022-10-19T05:44:13.392163",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.345879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98686ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.413037Z",
     "iopub.status.busy": "2022-10-19T05:44:13.412219Z",
     "iopub.status.idle": "2022-10-19T05:44:13.432041Z",
     "shell.execute_reply": "2022-10-19T05:44:13.430626Z"
    },
    "papermill": {
     "duration": 0.032633,
     "end_time": "2022-10-19T05:44:13.434786",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.402153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8054734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.454689Z",
     "iopub.status.busy": "2022-10-19T05:44:13.454205Z",
     "iopub.status.idle": "2022-10-19T05:44:13.463512Z",
     "shell.execute_reply": "2022-10-19T05:44:13.462367Z"
    },
    "papermill": {
     "duration": 0.022381,
     "end_time": "2022-10-19T05:44:13.465914",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.443533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Exited\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1abfaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.486168Z",
     "iopub.status.busy": "2022-10-19T05:44:13.485307Z",
     "iopub.status.idle": "2022-10-19T05:44:13.494822Z",
     "shell.execute_reply": "2022-10-19T05:44:13.493382Z"
    },
    "papermill": {
     "duration": 0.022656,
     "end_time": "2022-10-19T05:44:13.497278",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.474622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Geography\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219202b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.517551Z",
     "iopub.status.busy": "2022-10-19T05:44:13.516793Z",
     "iopub.status.idle": "2022-10-19T05:44:13.527259Z",
     "shell.execute_reply": "2022-10-19T05:44:13.526292Z"
    },
    "papermill": {
     "duration": 0.023013,
     "end_time": "2022-10-19T05:44:13.529384",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.506371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37    478\n",
       "38    477\n",
       "35    474\n",
       "36    456\n",
       "34    447\n",
       "     ... \n",
       "92      2\n",
       "82      1\n",
       "88      1\n",
       "85      1\n",
       "83      1\n",
       "Name: Age, Length: 70, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfaf6495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.549818Z",
     "iopub.status.busy": "2022-10-19T05:44:13.548593Z",
     "iopub.status.idle": "2022-10-19T05:44:13.559537Z",
     "shell.execute_reply": "2022-10-19T05:44:13.558161Z"
    },
    "papermill": {
     "duration": 0.023818,
     "end_time": "2022-10-19T05:44:13.562052",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.538234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd6f0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.581734Z",
     "iopub.status.busy": "2022-10-19T05:44:13.581251Z",
     "iopub.status.idle": "2022-10-19T05:44:13.591474Z",
     "shell.execute_reply": "2022-10-19T05:44:13.590066Z"
    },
    "papermill": {
     "duration": 0.023029,
     "end_time": "2022-10-19T05:44:13.593899",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.570870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['RowNumber','CustomerId','Surname'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d49ae05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.614364Z",
     "iopub.status.busy": "2022-10-19T05:44:13.613877Z",
     "iopub.status.idle": "2022-10-19T05:44:13.632862Z",
     "shell.execute_reply": "2022-10-19T05:44:13.631399Z"
    },
    "papermill": {
     "duration": 0.032528,
     "end_time": "2022-10-19T05:44:13.635390",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.602862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf4b239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.656408Z",
     "iopub.status.busy": "2022-10-19T05:44:13.655838Z",
     "iopub.status.idle": "2022-10-19T05:44:13.705576Z",
     "shell.execute_reply": "2022-10-19T05:44:13.704079Z"
    },
    "papermill": {
     "duration": 0.063321,
     "end_time": "2022-10-19T05:44:13.708234",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.644913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore           Age        Tenure        Balance  NumOfProducts  \\\n",
       "count  10000.000000  10000.000000  10000.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800      5.012800   76485.889288       1.530200   \n",
       "std       96.653299     10.487806      2.892174   62397.405202       0.581654   \n",
       "min      350.000000     18.000000      0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000      3.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000      5.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000      7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000     10.000000  250898.090000       4.000000   \n",
       "\n",
       "         HasCrCard  IsActiveMember  EstimatedSalary        Exited  \n",
       "count  10000.00000    10000.000000     10000.000000  10000.000000  \n",
       "mean       0.70550        0.515100    100090.239881      0.203700  \n",
       "std        0.45584        0.499797     57510.492818      0.402769  \n",
       "min        0.00000        0.000000        11.580000      0.000000  \n",
       "25%        0.00000        0.000000     51002.110000      0.000000  \n",
       "50%        1.00000        1.000000    100193.915000      0.000000  \n",
       "75%        1.00000        1.000000    149388.247500      0.000000  \n",
       "max        1.00000        1.000000    199992.480000      1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6c52d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.730122Z",
     "iopub.status.busy": "2022-10-19T05:44:13.729414Z",
     "iopub.status.idle": "2022-10-19T05:44:13.745006Z",
     "shell.execute_reply": "2022-10-19T05:44:13.743704Z"
    },
    "papermill": {
     "duration": 0.02993,
     "end_time": "2022-10-19T05:44:13.747870",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.717940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df,columns=['Geography','Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1525fd80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.769966Z",
     "iopub.status.busy": "2022-10-19T05:44:13.769040Z",
     "iopub.status.idle": "2022-10-19T05:44:13.787080Z",
     "shell.execute_reply": "2022-10-19T05:44:13.785646Z"
    },
    "papermill": {
     "duration": 0.031848,
     "end_time": "2022-10-19T05:44:13.789482",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.757634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "947b0432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:13.810813Z",
     "iopub.status.busy": "2022-10-19T05:44:13.810267Z",
     "iopub.status.idle": "2022-10-19T05:44:15.178726Z",
     "shell.execute_reply": "2022-10-19T05:44:15.177616Z"
    },
    "papermill": {
     "duration": 1.382368,
     "end_time": "2022-10-19T05:44:15.181345",
     "exception": false,
     "start_time": "2022-10-19T05:44:13.798977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(columns=['Exited'])\n",
    "y=df['Exited']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfa0e57c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:15.203298Z",
     "iopub.status.busy": "2022-10-19T05:44:15.202450Z",
     "iopub.status.idle": "2022-10-19T05:44:15.222997Z",
     "shell.execute_reply": "2022-10-19T05:44:15.222119Z"
    },
    "papermill": {
     "duration": 0.03424,
     "end_time": "2022-10-19T05:44:15.225181",
     "exception": false,
     "start_time": "2022-10-19T05:44:15.190941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "0                  1        101348.88                  0                0   \n",
       "1                  1        112542.58                  0                1   \n",
       "2                  0        113931.57                  0                0   \n",
       "3                  0         93826.63                  0                0   \n",
       "4                  1         79084.10                  0                1   \n",
       "...              ...              ...                ...              ...   \n",
       "9995               0         96270.64                  0                0   \n",
       "9996               1        101699.77                  0                0   \n",
       "9997               1         42085.58                  0                0   \n",
       "9998               0         92888.52                  1                0   \n",
       "9999               0         38190.78                  0                0   \n",
       "\n",
       "      Gender_Male  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "9995            1  \n",
       "9996            1  \n",
       "9997            0  \n",
       "9998            1  \n",
       "9999            0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000b1af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:15.247969Z",
     "iopub.status.busy": "2022-10-19T05:44:15.246904Z",
     "iopub.status.idle": "2022-10-19T05:44:15.256838Z",
     "shell.execute_reply": "2022-10-19T05:44:15.255540Z"
    },
    "papermill": {
     "duration": 0.023856,
     "end_time": "2022-10-19T05:44:15.259023",
     "exception": false,
     "start_time": "2022-10-19T05:44:15.235167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def3e9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:15.281680Z",
     "iopub.status.busy": "2022-10-19T05:44:15.280816Z",
     "iopub.status.idle": "2022-10-19T05:44:15.298115Z",
     "shell.execute_reply": "2022-10-19T05:44:15.296543Z"
    },
    "papermill": {
     "duration": 0.032218,
     "end_time": "2022-10-19T05:44:15.301115",
     "exception": false,
     "start_time": "2022-10-19T05:44:15.268897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x_train_scaled=scaler.fit_transform(X_train)\n",
    "x_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53cb1886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:15.323633Z",
     "iopub.status.busy": "2022-10-19T05:44:15.323123Z",
     "iopub.status.idle": "2022-10-19T05:44:15.332418Z",
     "shell.execute_reply": "2022-10-19T05:44:15.331145Z"
    },
    "papermill": {
     "duration": 0.02362,
     "end_time": "2022-10-19T05:44:15.334853",
     "exception": false,
     "start_time": "2022-10-19T05:44:15.311233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35649971, -0.6557859 ,  0.34567966, ..., -0.57946723,\n",
       "        -0.57638802,  0.91324755],\n",
       "       [-0.20389777,  0.29493847, -0.3483691 , ...,  1.72572313,\n",
       "        -0.57638802,  0.91324755],\n",
       "       [-0.96147213, -1.41636539, -0.69539349, ..., -0.57946723,\n",
       "         1.73494238,  0.91324755],\n",
       "       ...,\n",
       "       [ 0.86500853, -0.08535128, -1.38944225, ..., -0.57946723,\n",
       "        -0.57638802, -1.09499335],\n",
       "       [ 0.15932282,  0.3900109 ,  1.03972843, ..., -0.57946723,\n",
       "        -0.57638802,  0.91324755],\n",
       "       [ 0.47065475,  1.15059039, -1.38944225, ...,  1.72572313,\n",
       "        -0.57638802,  0.91324755]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31083506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:15.359616Z",
     "iopub.status.busy": "2022-10-19T05:44:15.358313Z",
     "iopub.status.idle": "2022-10-19T05:44:23.110242Z",
     "shell.execute_reply": "2022-10-19T05:44:23.109069Z"
    },
    "papermill": {
     "duration": 7.767195,
     "end_time": "2022-10-19T05:44:23.112908",
     "exception": false,
     "start_time": "2022-10-19T05:44:15.345713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ac31d9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:23.136865Z",
     "iopub.status.busy": "2022-10-19T05:44:23.135122Z",
     "iopub.status.idle": "2022-10-19T05:44:23.872332Z",
     "shell.execute_reply": "2022-10-19T05:44:23.870918Z"
    },
    "papermill": {
     "duration": 0.752025,
     "end_time": "2022-10-19T05:44:23.875289",
     "exception": false,
     "start_time": "2022-10-19T05:44:23.123264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 05:44:23.181568: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "for i in range(1,20):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(i,activation='relu',input_dim=11))\n",
    "    model.add(Dense(i,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa2fc0be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:23.900911Z",
     "iopub.status.busy": "2022-10-19T05:44:23.899939Z",
     "iopub.status.idle": "2022-10-19T05:44:23.908825Z",
     "shell.execute_reply": "2022-10-19T05:44:23.906786Z"
    },
    "papermill": {
     "duration": 0.024736,
     "end_time": "2022-10-19T05:44:23.911873",
     "exception": false,
     "start_time": "2022-10-19T05:44:23.887137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[9].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aabb8c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:44:23.936718Z",
     "iopub.status.busy": "2022-10-19T05:44:23.936250Z",
     "iopub.status.idle": "2022-10-19T05:59:25.484115Z",
     "shell.execute_reply": "2022-10-19T05:59:25.482772Z"
    },
    "papermill": {
     "duration": 901.563777,
     "end_time": "2022-10-19T05:59:25.486814",
     "exception": false,
     "start_time": "2022-10-19T05:44:23.923037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 05:44:24.069905: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6188 - accuracy: 0.7934 - val_loss: 0.5599 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7934 - val_loss: 0.4970 - val_accuracy: 0.7987\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7934 - val_loss: 0.4779 - val_accuracy: 0.7987\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7934 - val_loss: 0.4697 - val_accuracy: 0.7987\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7934 - val_loss: 0.4639 - val_accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7934 - val_loss: 0.4594 - val_accuracy: 0.7987\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7934 - val_loss: 0.4548 - val_accuracy: 0.7987\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7934 - val_loss: 0.4503 - val_accuracy: 0.7987\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7934 - val_loss: 0.4457 - val_accuracy: 0.7987\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7934 - val_loss: 0.4411 - val_accuracy: 0.7987\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7934 - val_loss: 0.4371 - val_accuracy: 0.7987\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.4342 - val_accuracy: 0.7987\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.4319 - val_accuracy: 0.7987\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7934 - val_loss: 0.4300 - val_accuracy: 0.7987\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.4285 - val_accuracy: 0.7987\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.4275 - val_accuracy: 0.7987\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4268 - val_accuracy: 0.7987\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7934 - val_loss: 0.4266 - val_accuracy: 0.7987\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.4264 - val_accuracy: 0.7987\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.7934 - val_loss: 0.4261 - val_accuracy: 0.7987\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4338 - accuracy: 0.7934 - val_loss: 0.4259 - val_accuracy: 0.7987\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.4335 - accuracy: 0.7934 - val_loss: 0.4257 - val_accuracy: 0.7987\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7934 - val_loss: 0.4255 - val_accuracy: 0.7987\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7934 - val_loss: 0.4252 - val_accuracy: 0.7987\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.4251 - val_accuracy: 0.7987\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7934 - val_loss: 0.4248 - val_accuracy: 0.7987\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.4247 - val_accuracy: 0.7987\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.4245 - val_accuracy: 0.7987\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.4244 - val_accuracy: 0.7987\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7934 - val_loss: 0.4244 - val_accuracy: 0.7987\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4245 - val_accuracy: 0.7987\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4241 - val_accuracy: 0.7987\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4240 - val_accuracy: 0.7987\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4239 - val_accuracy: 0.7987\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4238 - val_accuracy: 0.7987\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4238 - val_accuracy: 0.7987\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4238 - val_accuracy: 0.7987\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4237 - val_accuracy: 0.7987\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4237 - val_accuracy: 0.7987\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4236 - val_accuracy: 0.7987\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4236 - val_accuracy: 0.7987\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7945 - val_loss: 0.4235 - val_accuracy: 0.7987\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7928 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7920 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4232 - val_accuracy: 0.7987\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7925 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7922 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4232 - val_accuracy: 0.7987\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4325 - accuracy: 0.7914 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4326 - accuracy: 0.7917 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7916 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7919 - val_loss: 0.4232 - val_accuracy: 0.7987\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7942 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4232 - val_accuracy: 0.7987\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6624 - accuracy: 0.6886 - val_loss: 0.6214 - val_accuracy: 0.8037\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5949 - accuracy: 0.7950 - val_loss: 0.5652 - val_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7939 - val_loss: 0.5211 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7942 - val_loss: 0.4992 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7964 - val_loss: 0.4893 - val_accuracy: 0.8075\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8028 - val_loss: 0.4806 - val_accuracy: 0.8119\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8095 - val_loss: 0.4693 - val_accuracy: 0.8150\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8142 - val_loss: 0.4490 - val_accuracy: 0.8188\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8153 - val_loss: 0.4289 - val_accuracy: 0.8250\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8202 - val_loss: 0.4152 - val_accuracy: 0.8281\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8227 - val_loss: 0.4042 - val_accuracy: 0.8388\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8298 - val_loss: 0.3971 - val_accuracy: 0.8400\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8342 - val_loss: 0.3922 - val_accuracy: 0.8419\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8389 - val_loss: 0.3878 - val_accuracy: 0.8413\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8383 - val_loss: 0.3846 - val_accuracy: 0.8419\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8406 - val_loss: 0.3830 - val_accuracy: 0.8462\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8408 - val_loss: 0.3799 - val_accuracy: 0.8438\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8417 - val_loss: 0.3776 - val_accuracy: 0.8444\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8420 - val_loss: 0.3758 - val_accuracy: 0.8456\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8442 - val_loss: 0.3741 - val_accuracy: 0.8450\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8434 - val_loss: 0.3728 - val_accuracy: 0.8456\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8417 - val_loss: 0.3719 - val_accuracy: 0.8456\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8444 - val_loss: 0.3712 - val_accuracy: 0.8462\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8436 - val_loss: 0.3716 - val_accuracy: 0.8487\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8448 - val_loss: 0.3704 - val_accuracy: 0.8469\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8423 - val_loss: 0.3703 - val_accuracy: 0.8475\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8455 - val_loss: 0.3693 - val_accuracy: 0.8444\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8417 - val_loss: 0.3691 - val_accuracy: 0.8444\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8444 - val_loss: 0.3693 - val_accuracy: 0.8494\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8422 - val_loss: 0.3687 - val_accuracy: 0.8450\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8433 - val_loss: 0.3682 - val_accuracy: 0.8438\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8430 - val_loss: 0.3681 - val_accuracy: 0.8450\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8444 - val_loss: 0.3684 - val_accuracy: 0.8456\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8445 - val_loss: 0.3676 - val_accuracy: 0.8444\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8441 - val_loss: 0.3673 - val_accuracy: 0.8438\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8444 - val_loss: 0.3671 - val_accuracy: 0.8444\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8450 - val_loss: 0.3668 - val_accuracy: 0.8456\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8445 - val_loss: 0.3669 - val_accuracy: 0.8456\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8444 - val_loss: 0.3666 - val_accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8438 - val_loss: 0.3668 - val_accuracy: 0.8444\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8431 - val_loss: 0.3664 - val_accuracy: 0.8444\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8448 - val_loss: 0.3663 - val_accuracy: 0.8444\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8453 - val_loss: 0.3662 - val_accuracy: 0.8444\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8453 - val_loss: 0.3660 - val_accuracy: 0.8450\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8455 - val_loss: 0.3663 - val_accuracy: 0.8438\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8433 - val_loss: 0.3657 - val_accuracy: 0.8444\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8450 - val_loss: 0.3658 - val_accuracy: 0.8444\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8452 - val_loss: 0.3655 - val_accuracy: 0.8438\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8438 - val_loss: 0.3653 - val_accuracy: 0.8450\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8447 - val_loss: 0.3656 - val_accuracy: 0.8462\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8450 - val_loss: 0.3656 - val_accuracy: 0.8444\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8447 - val_loss: 0.3651 - val_accuracy: 0.8444\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8459 - val_loss: 0.3657 - val_accuracy: 0.8444\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8447 - val_loss: 0.3653 - val_accuracy: 0.8438\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8450 - val_loss: 0.3650 - val_accuracy: 0.8438\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8439 - val_loss: 0.3650 - val_accuracy: 0.8450\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3644 - accuracy: 0.8438 - val_loss: 0.3664 - val_accuracy: 0.8475\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8436 - val_loss: 0.3654 - val_accuracy: 0.8444\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8455 - val_loss: 0.3651 - val_accuracy: 0.8438\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8433 - val_loss: 0.3647 - val_accuracy: 0.8444\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8445 - val_loss: 0.3659 - val_accuracy: 0.8450\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8442 - val_loss: 0.3648 - val_accuracy: 0.8450\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8450 - val_loss: 0.3650 - val_accuracy: 0.8438\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8448 - val_loss: 0.3652 - val_accuracy: 0.8438\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8444 - val_loss: 0.3654 - val_accuracy: 0.8438\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8442 - val_loss: 0.3646 - val_accuracy: 0.8462\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8434 - val_loss: 0.3652 - val_accuracy: 0.8438\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8431 - val_loss: 0.3647 - val_accuracy: 0.8431\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8442 - val_loss: 0.3646 - val_accuracy: 0.8438\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8442 - val_loss: 0.3646 - val_accuracy: 0.8425\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8438 - val_loss: 0.3646 - val_accuracy: 0.8456\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8442 - val_loss: 0.3643 - val_accuracy: 0.8450\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8448 - val_loss: 0.3649 - val_accuracy: 0.8431\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8452 - val_loss: 0.3644 - val_accuracy: 0.8444\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8448 - val_loss: 0.3641 - val_accuracy: 0.8462\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8444 - val_loss: 0.3646 - val_accuracy: 0.8438\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8450 - val_loss: 0.3647 - val_accuracy: 0.8431\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8433 - val_loss: 0.3641 - val_accuracy: 0.8444\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8447 - val_loss: 0.3644 - val_accuracy: 0.8438\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8455 - val_loss: 0.3638 - val_accuracy: 0.8444\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8438 - val_loss: 0.3641 - val_accuracy: 0.8450\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8450 - val_loss: 0.3651 - val_accuracy: 0.8444\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8441 - val_loss: 0.3638 - val_accuracy: 0.8444\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8450 - val_loss: 0.3636 - val_accuracy: 0.8444\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8442 - val_loss: 0.3639 - val_accuracy: 0.8444\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8434 - val_loss: 0.3637 - val_accuracy: 0.8438\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8441 - val_loss: 0.3640 - val_accuracy: 0.8438\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8438 - val_loss: 0.3637 - val_accuracy: 0.8444\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8462 - val_loss: 0.3640 - val_accuracy: 0.8444\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8453 - val_loss: 0.3639 - val_accuracy: 0.8450\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8428 - val_loss: 0.3634 - val_accuracy: 0.8444\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8441 - val_loss: 0.3649 - val_accuracy: 0.8438\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8441 - val_loss: 0.3643 - val_accuracy: 0.8450\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8456 - val_loss: 0.3646 - val_accuracy: 0.8456\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8450 - val_loss: 0.3635 - val_accuracy: 0.8444\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8452 - val_loss: 0.3637 - val_accuracy: 0.8444\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8452 - val_loss: 0.3641 - val_accuracy: 0.8462\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8438 - val_loss: 0.3638 - val_accuracy: 0.8450\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8430 - val_loss: 0.3635 - val_accuracy: 0.8450\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8450 - val_loss: 0.3639 - val_accuracy: 0.8438\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5757 - accuracy: 0.7525 - val_loss: 0.4967 - val_accuracy: 0.8106\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7958 - val_loss: 0.4645 - val_accuracy: 0.8112\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7972 - val_loss: 0.4510 - val_accuracy: 0.8125\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7997 - val_loss: 0.4419 - val_accuracy: 0.8144\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8030 - val_loss: 0.4360 - val_accuracy: 0.8169\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8058 - val_loss: 0.4320 - val_accuracy: 0.8188\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8073 - val_loss: 0.4294 - val_accuracy: 0.8225\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8109 - val_loss: 0.4273 - val_accuracy: 0.8244\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8133 - val_loss: 0.4253 - val_accuracy: 0.8219\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8145 - val_loss: 0.4235 - val_accuracy: 0.8213\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8136 - val_loss: 0.4220 - val_accuracy: 0.8244\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8144 - val_loss: 0.4206 - val_accuracy: 0.8263\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8155 - val_loss: 0.4186 - val_accuracy: 0.8288\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8163 - val_loss: 0.4168 - val_accuracy: 0.8300\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8181 - val_loss: 0.4153 - val_accuracy: 0.8294\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8209 - val_loss: 0.4134 - val_accuracy: 0.8331\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8233 - val_loss: 0.4120 - val_accuracy: 0.8319\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8244 - val_loss: 0.4103 - val_accuracy: 0.8319\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8259 - val_loss: 0.4087 - val_accuracy: 0.8331\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8286 - val_loss: 0.4070 - val_accuracy: 0.8331\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8308 - val_loss: 0.4056 - val_accuracy: 0.8331\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.8309 - val_loss: 0.4047 - val_accuracy: 0.8325\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8317 - val_loss: 0.4037 - val_accuracy: 0.8319\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8323 - val_loss: 0.4031 - val_accuracy: 0.8319\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8333 - val_loss: 0.4029 - val_accuracy: 0.8319\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8325 - val_loss: 0.4022 - val_accuracy: 0.8313\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8320 - val_loss: 0.4017 - val_accuracy: 0.8338\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.4066 - accuracy: 0.8338 - val_loss: 0.4014 - val_accuracy: 0.8344\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8334 - val_loss: 0.4016 - val_accuracy: 0.8344\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8330 - val_loss: 0.4008 - val_accuracy: 0.8344\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8338 - val_loss: 0.4008 - val_accuracy: 0.8356\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8334 - val_loss: 0.4001 - val_accuracy: 0.8375\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8345 - val_loss: 0.4001 - val_accuracy: 0.8369\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8322 - val_loss: 0.3992 - val_accuracy: 0.8381\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8359 - val_loss: 0.3985 - val_accuracy: 0.8388\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8355 - val_loss: 0.3975 - val_accuracy: 0.8388\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8342 - val_loss: 0.3961 - val_accuracy: 0.8388\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8330 - val_loss: 0.3946 - val_accuracy: 0.8388\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8320 - val_loss: 0.3924 - val_accuracy: 0.8369\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8325 - val_loss: 0.3903 - val_accuracy: 0.8363\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8330 - val_loss: 0.3880 - val_accuracy: 0.8350\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8333 - val_loss: 0.3857 - val_accuracy: 0.8363\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8348 - val_loss: 0.3837 - val_accuracy: 0.8394\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8398 - val_loss: 0.3813 - val_accuracy: 0.8394\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8416 - val_loss: 0.3796 - val_accuracy: 0.8381\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8431 - val_loss: 0.3776 - val_accuracy: 0.8406\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8427 - val_loss: 0.3772 - val_accuracy: 0.8444\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8444 - val_loss: 0.3756 - val_accuracy: 0.8413\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8450 - val_loss: 0.3751 - val_accuracy: 0.8425\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8466 - val_loss: 0.3733 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8475 - val_loss: 0.3721 - val_accuracy: 0.8456\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8498 - val_loss: 0.3713 - val_accuracy: 0.8481\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8495 - val_loss: 0.3696 - val_accuracy: 0.8456\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8511 - val_loss: 0.3685 - val_accuracy: 0.8487\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8512 - val_loss: 0.3680 - val_accuracy: 0.8481\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8498 - val_loss: 0.3675 - val_accuracy: 0.8469\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8514 - val_loss: 0.3662 - val_accuracy: 0.8475\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8544 - val_loss: 0.3665 - val_accuracy: 0.8487\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8506 - val_loss: 0.3659 - val_accuracy: 0.8487\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8537 - val_loss: 0.3650 - val_accuracy: 0.8494\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8541 - val_loss: 0.3640 - val_accuracy: 0.8519\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8517 - val_loss: 0.3632 - val_accuracy: 0.8512\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8548 - val_loss: 0.3630 - val_accuracy: 0.8494\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8547 - val_loss: 0.3629 - val_accuracy: 0.8469\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8561 - val_loss: 0.3613 - val_accuracy: 0.8456\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8561 - val_loss: 0.3623 - val_accuracy: 0.8519\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8559 - val_loss: 0.3607 - val_accuracy: 0.8519\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8555 - val_loss: 0.3606 - val_accuracy: 0.8525\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8542 - val_loss: 0.3598 - val_accuracy: 0.8544\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8562 - val_loss: 0.3606 - val_accuracy: 0.8512\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8561 - val_loss: 0.3602 - val_accuracy: 0.8537\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8541 - val_loss: 0.3605 - val_accuracy: 0.8537\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8545 - val_loss: 0.3607 - val_accuracy: 0.8500\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8541 - val_loss: 0.3589 - val_accuracy: 0.8519\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8575 - val_loss: 0.3592 - val_accuracy: 0.8550\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8542 - val_loss: 0.3588 - val_accuracy: 0.8500\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8564 - val_loss: 0.3578 - val_accuracy: 0.8469\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8561 - val_loss: 0.3588 - val_accuracy: 0.8519\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8555 - val_loss: 0.3577 - val_accuracy: 0.8481\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8555 - val_loss: 0.3570 - val_accuracy: 0.8506\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8550 - val_loss: 0.3567 - val_accuracy: 0.8525\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8572 - val_loss: 0.3557 - val_accuracy: 0.8544\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8561 - val_loss: 0.3553 - val_accuracy: 0.8494\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8567 - val_loss: 0.3557 - val_accuracy: 0.8487\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8586 - val_loss: 0.3560 - val_accuracy: 0.8537\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8570 - val_loss: 0.3550 - val_accuracy: 0.8512\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8564 - val_loss: 0.3562 - val_accuracy: 0.8506\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8575 - val_loss: 0.3543 - val_accuracy: 0.8494\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8569 - val_loss: 0.3541 - val_accuracy: 0.8500\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8566 - val_loss: 0.3553 - val_accuracy: 0.8481\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8558 - val_loss: 0.3551 - val_accuracy: 0.8462\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8587 - val_loss: 0.3562 - val_accuracy: 0.8500\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8566 - val_loss: 0.3535 - val_accuracy: 0.8506\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8584 - val_loss: 0.3541 - val_accuracy: 0.8481\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8572 - val_loss: 0.3526 - val_accuracy: 0.8487\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8575 - val_loss: 0.3529 - val_accuracy: 0.8512\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8575 - val_loss: 0.3533 - val_accuracy: 0.8519\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8575 - val_loss: 0.3520 - val_accuracy: 0.8487\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8580 - val_loss: 0.3536 - val_accuracy: 0.8462\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3459 - accuracy: 0.8577 - val_loss: 0.3517 - val_accuracy: 0.8519\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5731 - accuracy: 0.7608 - val_loss: 0.5041 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7934 - val_loss: 0.4717 - val_accuracy: 0.7987\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7934 - val_loss: 0.4573 - val_accuracy: 0.7987\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7934 - val_loss: 0.4476 - val_accuracy: 0.7987\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7934 - val_loss: 0.4414 - val_accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.4367 - val_accuracy: 0.7987\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7934 - val_loss: 0.4331 - val_accuracy: 0.7987\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4300 - val_accuracy: 0.7987\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.4273 - val_accuracy: 0.7987\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.4251 - val_accuracy: 0.7987\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7934 - val_loss: 0.4230 - val_accuracy: 0.7987\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7934 - val_loss: 0.4209 - val_accuracy: 0.7987\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8156 - val_loss: 0.4192 - val_accuracy: 0.8306\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8198 - val_loss: 0.4178 - val_accuracy: 0.8306\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8219 - val_loss: 0.4166 - val_accuracy: 0.8331\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8247 - val_loss: 0.4153 - val_accuracy: 0.8338\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8256 - val_loss: 0.4144 - val_accuracy: 0.8313\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8288 - val_loss: 0.4142 - val_accuracy: 0.8313\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8292 - val_loss: 0.4131 - val_accuracy: 0.8306\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8295 - val_loss: 0.4130 - val_accuracy: 0.8306\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8292 - val_loss: 0.4120 - val_accuracy: 0.8300\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8314 - val_loss: 0.4114 - val_accuracy: 0.8319\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8291 - val_loss: 0.4109 - val_accuracy: 0.8331\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8316 - val_loss: 0.4112 - val_accuracy: 0.8338\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8316 - val_loss: 0.4100 - val_accuracy: 0.8331\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8325 - val_loss: 0.4095 - val_accuracy: 0.8356\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8331 - val_loss: 0.4088 - val_accuracy: 0.8356\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8334 - val_loss: 0.4086 - val_accuracy: 0.8375\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8342 - val_loss: 0.4081 - val_accuracy: 0.8381\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8356 - val_loss: 0.4079 - val_accuracy: 0.8369\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8361 - val_loss: 0.4077 - val_accuracy: 0.8369\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8366 - val_loss: 0.4078 - val_accuracy: 0.8363\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8375 - val_loss: 0.4069 - val_accuracy: 0.8363\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8372 - val_loss: 0.4070 - val_accuracy: 0.8375\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8377 - val_loss: 0.4063 - val_accuracy: 0.8375\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8367 - val_loss: 0.4060 - val_accuracy: 0.8363\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8380 - val_loss: 0.4059 - val_accuracy: 0.8356\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8373 - val_loss: 0.4057 - val_accuracy: 0.8375\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8369 - val_loss: 0.4052 - val_accuracy: 0.8375\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8380 - val_loss: 0.4047 - val_accuracy: 0.8363\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8380 - val_loss: 0.4042 - val_accuracy: 0.8356\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8367 - val_loss: 0.4039 - val_accuracy: 0.8363\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8377 - val_loss: 0.4040 - val_accuracy: 0.8363\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8380 - val_loss: 0.4035 - val_accuracy: 0.8350\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8381 - val_loss: 0.4030 - val_accuracy: 0.8356\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8383 - val_loss: 0.4027 - val_accuracy: 0.8350\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8391 - val_loss: 0.4024 - val_accuracy: 0.8344\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8378 - val_loss: 0.4028 - val_accuracy: 0.8356\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8391 - val_loss: 0.4017 - val_accuracy: 0.8363\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8380 - val_loss: 0.4025 - val_accuracy: 0.8369\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8384 - val_loss: 0.4015 - val_accuracy: 0.8356\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8397 - val_loss: 0.4011 - val_accuracy: 0.8375\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8380 - val_loss: 0.4013 - val_accuracy: 0.8356\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8377 - val_loss: 0.4011 - val_accuracy: 0.8363\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8394 - val_loss: 0.4014 - val_accuracy: 0.8363\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8380 - val_loss: 0.4010 - val_accuracy: 0.8369\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8384 - val_loss: 0.4010 - val_accuracy: 0.8369\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8392 - val_loss: 0.4013 - val_accuracy: 0.8363\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8384 - val_loss: 0.4009 - val_accuracy: 0.8369\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8378 - val_loss: 0.4017 - val_accuracy: 0.8356\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8405 - val_loss: 0.4008 - val_accuracy: 0.8356\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8380 - val_loss: 0.4005 - val_accuracy: 0.8356\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8389 - val_loss: 0.4003 - val_accuracy: 0.8344\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8381 - val_loss: 0.4001 - val_accuracy: 0.8375\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8389 - val_loss: 0.4000 - val_accuracy: 0.8375\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8383 - val_loss: 0.3992 - val_accuracy: 0.8381\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8388 - val_loss: 0.3983 - val_accuracy: 0.8388\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8392 - val_loss: 0.3986 - val_accuracy: 0.8381\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8394 - val_loss: 0.3975 - val_accuracy: 0.8375\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8397 - val_loss: 0.3960 - val_accuracy: 0.8375\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8403 - val_loss: 0.3947 - val_accuracy: 0.8394\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3914 - accuracy: 0.8409 - val_loss: 0.3935 - val_accuracy: 0.8400\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3890 - accuracy: 0.8427 - val_loss: 0.3891 - val_accuracy: 0.8413\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3827 - accuracy: 0.8445 - val_loss: 0.3824 - val_accuracy: 0.8431\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8469 - val_loss: 0.3735 - val_accuracy: 0.8475\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8516 - val_loss: 0.3644 - val_accuracy: 0.8519\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8561 - val_loss: 0.3587 - val_accuracy: 0.8525\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8589 - val_loss: 0.3548 - val_accuracy: 0.8550\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8634 - val_loss: 0.3530 - val_accuracy: 0.8594\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8623 - val_loss: 0.3502 - val_accuracy: 0.8600\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8623 - val_loss: 0.3490 - val_accuracy: 0.8600\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8633 - val_loss: 0.3478 - val_accuracy: 0.8600\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8620 - val_loss: 0.3476 - val_accuracy: 0.8612\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8630 - val_loss: 0.3468 - val_accuracy: 0.8619\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8631 - val_loss: 0.3466 - val_accuracy: 0.8612\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8614 - val_loss: 0.3461 - val_accuracy: 0.8625\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8623 - val_loss: 0.3459 - val_accuracy: 0.8637\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8628 - val_loss: 0.3456 - val_accuracy: 0.8625\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8620 - val_loss: 0.3458 - val_accuracy: 0.8594\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8630 - val_loss: 0.3455 - val_accuracy: 0.8594\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8625 - val_loss: 0.3451 - val_accuracy: 0.8600\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8633 - val_loss: 0.3454 - val_accuracy: 0.8600\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8630 - val_loss: 0.3449 - val_accuracy: 0.8594\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8620 - val_loss: 0.3447 - val_accuracy: 0.8581\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8616 - val_loss: 0.3448 - val_accuracy: 0.8594\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8627 - val_loss: 0.3448 - val_accuracy: 0.8581\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8633 - val_loss: 0.3445 - val_accuracy: 0.8575\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8627 - val_loss: 0.3458 - val_accuracy: 0.8575\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8620 - val_loss: 0.3441 - val_accuracy: 0.8562\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8623 - val_loss: 0.3442 - val_accuracy: 0.8581\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6886 - accuracy: 0.5950 - val_loss: 0.5810 - val_accuracy: 0.7906\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7933 - val_loss: 0.5046 - val_accuracy: 0.7987\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7934 - val_loss: 0.4768 - val_accuracy: 0.7987\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7934 - val_loss: 0.4600 - val_accuracy: 0.7987\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7934 - val_loss: 0.4480 - val_accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7934 - val_loss: 0.4382 - val_accuracy: 0.7987\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7934 - val_loss: 0.4318 - val_accuracy: 0.7987\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.4275 - val_accuracy: 0.7987\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7934 - val_loss: 0.4250 - val_accuracy: 0.7987\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7934 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7934 - val_loss: 0.4208 - val_accuracy: 0.7987\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.4199 - val_accuracy: 0.7987\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8092 - val_loss: 0.4183 - val_accuracy: 0.8225\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8203 - val_loss: 0.4172 - val_accuracy: 0.8200\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8209 - val_loss: 0.4164 - val_accuracy: 0.8200\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8219 - val_loss: 0.4159 - val_accuracy: 0.8244\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8236 - val_loss: 0.4153 - val_accuracy: 0.8256\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8242 - val_loss: 0.4147 - val_accuracy: 0.8256\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8256 - val_loss: 0.4141 - val_accuracy: 0.8288\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8273 - val_loss: 0.4130 - val_accuracy: 0.8294\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8275 - val_loss: 0.4123 - val_accuracy: 0.8288\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8280 - val_loss: 0.4114 - val_accuracy: 0.8288\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8273 - val_loss: 0.4117 - val_accuracy: 0.8294\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8289 - val_loss: 0.4106 - val_accuracy: 0.8306\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8300 - val_loss: 0.4101 - val_accuracy: 0.8306\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8294 - val_loss: 0.4099 - val_accuracy: 0.8313\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8298 - val_loss: 0.4096 - val_accuracy: 0.8313\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8297 - val_loss: 0.4091 - val_accuracy: 0.8319\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8294 - val_loss: 0.4086 - val_accuracy: 0.8319\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8303 - val_loss: 0.4083 - val_accuracy: 0.8331\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8303 - val_loss: 0.4079 - val_accuracy: 0.8350\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8309 - val_loss: 0.4074 - val_accuracy: 0.8356\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8308 - val_loss: 0.4070 - val_accuracy: 0.8350\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8305 - val_loss: 0.4064 - val_accuracy: 0.8356\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8302 - val_loss: 0.4060 - val_accuracy: 0.8356\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8303 - val_loss: 0.4056 - val_accuracy: 0.8350\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8317 - val_loss: 0.4056 - val_accuracy: 0.8338\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8320 - val_loss: 0.4049 - val_accuracy: 0.8356\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8320 - val_loss: 0.4047 - val_accuracy: 0.8350\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8316 - val_loss: 0.4045 - val_accuracy: 0.8344\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8325 - val_loss: 0.4046 - val_accuracy: 0.8369\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8327 - val_loss: 0.4044 - val_accuracy: 0.8338\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4093 - accuracy: 0.8317 - val_loss: 0.4039 - val_accuracy: 0.8350\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8338 - val_loss: 0.4041 - val_accuracy: 0.8375\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8320 - val_loss: 0.4037 - val_accuracy: 0.8381\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8334 - val_loss: 0.4035 - val_accuracy: 0.8381\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8327 - val_loss: 0.4032 - val_accuracy: 0.8388\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8331 - val_loss: 0.4029 - val_accuracy: 0.8375\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4081 - accuracy: 0.8320 - val_loss: 0.4030 - val_accuracy: 0.8381\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8330 - val_loss: 0.4029 - val_accuracy: 0.8381\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8330 - val_loss: 0.4028 - val_accuracy: 0.8388\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8336 - val_loss: 0.4027 - val_accuracy: 0.8388\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8331 - val_loss: 0.4022 - val_accuracy: 0.8381\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8338 - val_loss: 0.4021 - val_accuracy: 0.8381\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8347 - val_loss: 0.4015 - val_accuracy: 0.8388\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8330 - val_loss: 0.4019 - val_accuracy: 0.8375\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8341 - val_loss: 0.4012 - val_accuracy: 0.8381\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8348 - val_loss: 0.4013 - val_accuracy: 0.8375\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8344 - val_loss: 0.4009 - val_accuracy: 0.8363\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8350 - val_loss: 0.4006 - val_accuracy: 0.8375\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8344 - val_loss: 0.4006 - val_accuracy: 0.8375\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8347 - val_loss: 0.4007 - val_accuracy: 0.8369\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8347 - val_loss: 0.4004 - val_accuracy: 0.8381\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8347 - val_loss: 0.4008 - val_accuracy: 0.8350\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8356 - val_loss: 0.4003 - val_accuracy: 0.8356\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8350 - val_loss: 0.3998 - val_accuracy: 0.8363\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8361 - val_loss: 0.3996 - val_accuracy: 0.8356\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8356 - val_loss: 0.3999 - val_accuracy: 0.8369\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8366 - val_loss: 0.4002 - val_accuracy: 0.8350\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8348 - val_loss: 0.3997 - val_accuracy: 0.8369\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8352 - val_loss: 0.3992 - val_accuracy: 0.8363\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8363 - val_loss: 0.3995 - val_accuracy: 0.8356\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8359 - val_loss: 0.3991 - val_accuracy: 0.8369\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8369 - val_loss: 0.3999 - val_accuracy: 0.8369\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8359 - val_loss: 0.3989 - val_accuracy: 0.8356\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8370 - val_loss: 0.3990 - val_accuracy: 0.8356\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8370 - val_loss: 0.3992 - val_accuracy: 0.8363\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8361 - val_loss: 0.3986 - val_accuracy: 0.8350\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8378 - val_loss: 0.3983 - val_accuracy: 0.8344\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8352 - val_loss: 0.3985 - val_accuracy: 0.8350\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8363 - val_loss: 0.3984 - val_accuracy: 0.8350\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8364 - val_loss: 0.3983 - val_accuracy: 0.8350\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8364 - val_loss: 0.3981 - val_accuracy: 0.8356\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8361 - val_loss: 0.3990 - val_accuracy: 0.8369\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8375 - val_loss: 0.3980 - val_accuracy: 0.8338\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8378 - val_loss: 0.3979 - val_accuracy: 0.8344\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8369 - val_loss: 0.3985 - val_accuracy: 0.8356\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8378 - val_loss: 0.3981 - val_accuracy: 0.8356\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8372 - val_loss: 0.3985 - val_accuracy: 0.8344\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8378 - val_loss: 0.3983 - val_accuracy: 0.8363\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8372 - val_loss: 0.3982 - val_accuracy: 0.8356\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8378 - val_loss: 0.3985 - val_accuracy: 0.8356\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8389 - val_loss: 0.3983 - val_accuracy: 0.8356\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8373 - val_loss: 0.3985 - val_accuracy: 0.8350\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8381 - val_loss: 0.3982 - val_accuracy: 0.8350\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8375 - val_loss: 0.3987 - val_accuracy: 0.8375\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8370 - val_loss: 0.3985 - val_accuracy: 0.8356\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8388 - val_loss: 0.3982 - val_accuracy: 0.8369\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8384 - val_loss: 0.3979 - val_accuracy: 0.8369\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8384 - val_loss: 0.3981 - val_accuracy: 0.8363\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5666 - accuracy: 0.7545 - val_loss: 0.4976 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7934 - val_loss: 0.4579 - val_accuracy: 0.7987\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7934 - val_loss: 0.4417 - val_accuracy: 0.7981\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7930 - val_loss: 0.4340 - val_accuracy: 0.7975\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7936 - val_loss: 0.4297 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7948 - val_loss: 0.4262 - val_accuracy: 0.8050\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8016 - val_loss: 0.4238 - val_accuracy: 0.8087\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8062 - val_loss: 0.4218 - val_accuracy: 0.8175\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8119 - val_loss: 0.4195 - val_accuracy: 0.8219\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8169 - val_loss: 0.4166 - val_accuracy: 0.8281\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8197 - val_loss: 0.4134 - val_accuracy: 0.8306\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8214 - val_loss: 0.4112 - val_accuracy: 0.8331\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8248 - val_loss: 0.4082 - val_accuracy: 0.8356\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8261 - val_loss: 0.4057 - val_accuracy: 0.8344\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4082 - accuracy: 0.8288 - val_loss: 0.4032 - val_accuracy: 0.8369\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8314 - val_loss: 0.4010 - val_accuracy: 0.8381\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8334 - val_loss: 0.3990 - val_accuracy: 0.8363\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8347 - val_loss: 0.3976 - val_accuracy: 0.8369\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8352 - val_loss: 0.3964 - val_accuracy: 0.8369\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8355 - val_loss: 0.3957 - val_accuracy: 0.8375\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8353 - val_loss: 0.3954 - val_accuracy: 0.8369\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8358 - val_loss: 0.3947 - val_accuracy: 0.8375\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8358 - val_loss: 0.3934 - val_accuracy: 0.8381\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8355 - val_loss: 0.3928 - val_accuracy: 0.8369\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8364 - val_loss: 0.3920 - val_accuracy: 0.8381\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8366 - val_loss: 0.3907 - val_accuracy: 0.8400\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8383 - val_loss: 0.3902 - val_accuracy: 0.8400\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8361 - val_loss: 0.3896 - val_accuracy: 0.8388\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8391 - val_loss: 0.3884 - val_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8381 - val_loss: 0.3873 - val_accuracy: 0.8388\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8405 - val_loss: 0.3873 - val_accuracy: 0.8369\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8405 - val_loss: 0.3865 - val_accuracy: 0.8369\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8406 - val_loss: 0.3851 - val_accuracy: 0.8350\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8388 - val_loss: 0.3847 - val_accuracy: 0.8344\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8403 - val_loss: 0.3842 - val_accuracy: 0.8344\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8411 - val_loss: 0.3828 - val_accuracy: 0.8394\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8413 - val_loss: 0.3821 - val_accuracy: 0.8400\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8411 - val_loss: 0.3819 - val_accuracy: 0.8388\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8417 - val_loss: 0.3810 - val_accuracy: 0.8388\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8441 - val_loss: 0.3792 - val_accuracy: 0.8425\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8438 - val_loss: 0.3791 - val_accuracy: 0.8369\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8444 - val_loss: 0.3785 - val_accuracy: 0.8400\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8453 - val_loss: 0.3770 - val_accuracy: 0.8450\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8466 - val_loss: 0.3759 - val_accuracy: 0.8431\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8469 - val_loss: 0.3752 - val_accuracy: 0.8456\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8470 - val_loss: 0.3743 - val_accuracy: 0.8438\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8480 - val_loss: 0.3739 - val_accuracy: 0.8413\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8481 - val_loss: 0.3730 - val_accuracy: 0.8456\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8487 - val_loss: 0.3719 - val_accuracy: 0.8456\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8503 - val_loss: 0.3717 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8506 - val_loss: 0.3702 - val_accuracy: 0.8475\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8517 - val_loss: 0.3705 - val_accuracy: 0.8462\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8517 - val_loss: 0.3688 - val_accuracy: 0.8481\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8559 - val_loss: 0.3678 - val_accuracy: 0.8500\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8527 - val_loss: 0.3690 - val_accuracy: 0.8487\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8541 - val_loss: 0.3665 - val_accuracy: 0.8487\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8559 - val_loss: 0.3659 - val_accuracy: 0.8475\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8558 - val_loss: 0.3652 - val_accuracy: 0.8475\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8547 - val_loss: 0.3647 - val_accuracy: 0.8500\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8566 - val_loss: 0.3639 - val_accuracy: 0.8481\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8564 - val_loss: 0.3635 - val_accuracy: 0.8475\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8561 - val_loss: 0.3620 - val_accuracy: 0.8506\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8580 - val_loss: 0.3622 - val_accuracy: 0.8494\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8562 - val_loss: 0.3613 - val_accuracy: 0.8494\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8592 - val_loss: 0.3604 - val_accuracy: 0.8531\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8586 - val_loss: 0.3605 - val_accuracy: 0.8494\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8584 - val_loss: 0.3594 - val_accuracy: 0.8512\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8573 - val_loss: 0.3595 - val_accuracy: 0.8506\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8581 - val_loss: 0.3593 - val_accuracy: 0.8531\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8581 - val_loss: 0.3581 - val_accuracy: 0.8512\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8595 - val_loss: 0.3582 - val_accuracy: 0.8519\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8575 - val_loss: 0.3572 - val_accuracy: 0.8519\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8587 - val_loss: 0.3576 - val_accuracy: 0.8519\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8589 - val_loss: 0.3579 - val_accuracy: 0.8512\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8597 - val_loss: 0.3567 - val_accuracy: 0.8556\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8598 - val_loss: 0.3567 - val_accuracy: 0.8550\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8598 - val_loss: 0.3562 - val_accuracy: 0.8562\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8598 - val_loss: 0.3548 - val_accuracy: 0.8537\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8602 - val_loss: 0.3555 - val_accuracy: 0.8500\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8603 - val_loss: 0.3550 - val_accuracy: 0.8525\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8589 - val_loss: 0.3558 - val_accuracy: 0.8544\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8586 - val_loss: 0.3547 - val_accuracy: 0.8525\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8603 - val_loss: 0.3533 - val_accuracy: 0.8531\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8608 - val_loss: 0.3545 - val_accuracy: 0.8512\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8612 - val_loss: 0.3536 - val_accuracy: 0.8556\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8597 - val_loss: 0.3537 - val_accuracy: 0.8537\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8595 - val_loss: 0.3542 - val_accuracy: 0.8525\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8627 - val_loss: 0.3527 - val_accuracy: 0.8537\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3399 - accuracy: 0.8581 - val_loss: 0.3532 - val_accuracy: 0.8519\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8597 - val_loss: 0.3521 - val_accuracy: 0.8544\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8609 - val_loss: 0.3527 - val_accuracy: 0.8519\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8620 - val_loss: 0.3525 - val_accuracy: 0.8506\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8606 - val_loss: 0.3531 - val_accuracy: 0.8500\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8597 - val_loss: 0.3516 - val_accuracy: 0.8512\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8619 - val_loss: 0.3523 - val_accuracy: 0.8537\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8600 - val_loss: 0.3519 - val_accuracy: 0.8544\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8584 - val_loss: 0.3525 - val_accuracy: 0.8556\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8619 - val_loss: 0.3529 - val_accuracy: 0.8487\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8620 - val_loss: 0.3514 - val_accuracy: 0.8519\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8608 - val_loss: 0.3517 - val_accuracy: 0.8512\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5986 - accuracy: 0.6961 - val_loss: 0.5165 - val_accuracy: 0.7956\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7905 - val_loss: 0.4742 - val_accuracy: 0.7994\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7931 - val_loss: 0.4526 - val_accuracy: 0.7994\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7944 - val_loss: 0.4406 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7958 - val_loss: 0.4333 - val_accuracy: 0.8006\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7978 - val_loss: 0.4283 - val_accuracy: 0.8031\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8036 - val_loss: 0.4239 - val_accuracy: 0.8062\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8103 - val_loss: 0.4196 - val_accuracy: 0.8144\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8163 - val_loss: 0.4141 - val_accuracy: 0.8213\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8203 - val_loss: 0.4069 - val_accuracy: 0.8275\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8309 - val_loss: 0.3981 - val_accuracy: 0.8344\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8398 - val_loss: 0.3872 - val_accuracy: 0.8394\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8484 - val_loss: 0.3764 - val_accuracy: 0.8450\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8527 - val_loss: 0.3671 - val_accuracy: 0.8481\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8570 - val_loss: 0.3619 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8580 - val_loss: 0.3577 - val_accuracy: 0.8531\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8598 - val_loss: 0.3561 - val_accuracy: 0.8525\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8603 - val_loss: 0.3536 - val_accuracy: 0.8556\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8603 - val_loss: 0.3526 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8602 - val_loss: 0.3518 - val_accuracy: 0.8550\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8617 - val_loss: 0.3523 - val_accuracy: 0.8562\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8598 - val_loss: 0.3523 - val_accuracy: 0.8569\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8591 - val_loss: 0.3524 - val_accuracy: 0.8544\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8598 - val_loss: 0.3526 - val_accuracy: 0.8544\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8586 - val_loss: 0.3527 - val_accuracy: 0.8556\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8589 - val_loss: 0.3521 - val_accuracy: 0.8537\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8603 - val_loss: 0.3516 - val_accuracy: 0.8537\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8594 - val_loss: 0.3515 - val_accuracy: 0.8556\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8600 - val_loss: 0.3517 - val_accuracy: 0.8550\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8592 - val_loss: 0.3519 - val_accuracy: 0.8562\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8589 - val_loss: 0.3513 - val_accuracy: 0.8544\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8606 - val_loss: 0.3516 - val_accuracy: 0.8569\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8602 - val_loss: 0.3510 - val_accuracy: 0.8537\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8611 - val_loss: 0.3510 - val_accuracy: 0.8562\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8595 - val_loss: 0.3502 - val_accuracy: 0.8550\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8609 - val_loss: 0.3497 - val_accuracy: 0.8569\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8608 - val_loss: 0.3493 - val_accuracy: 0.8550\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8605 - val_loss: 0.3486 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8623 - val_loss: 0.3485 - val_accuracy: 0.8562\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8617 - val_loss: 0.3484 - val_accuracy: 0.8556\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8614 - val_loss: 0.3479 - val_accuracy: 0.8556\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8625 - val_loss: 0.3481 - val_accuracy: 0.8544\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8619 - val_loss: 0.3480 - val_accuracy: 0.8544\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8642 - val_loss: 0.3482 - val_accuracy: 0.8550\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8617 - val_loss: 0.3478 - val_accuracy: 0.8531\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8622 - val_loss: 0.3473 - val_accuracy: 0.8556\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8614 - val_loss: 0.3487 - val_accuracy: 0.8537\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8627 - val_loss: 0.3476 - val_accuracy: 0.8531\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8625 - val_loss: 0.3472 - val_accuracy: 0.8544\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8631 - val_loss: 0.3474 - val_accuracy: 0.8544\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8633 - val_loss: 0.3475 - val_accuracy: 0.8519\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8616 - val_loss: 0.3477 - val_accuracy: 0.8537\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8622 - val_loss: 0.3481 - val_accuracy: 0.8525\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8619 - val_loss: 0.3478 - val_accuracy: 0.8550\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8637 - val_loss: 0.3480 - val_accuracy: 0.8537\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8631 - val_loss: 0.3488 - val_accuracy: 0.8537\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8637 - val_loss: 0.3474 - val_accuracy: 0.8556\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3322 - accuracy: 0.8631 - val_loss: 0.3476 - val_accuracy: 0.8550\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8619 - val_loss: 0.3481 - val_accuracy: 0.8556\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8631 - val_loss: 0.3481 - val_accuracy: 0.8544\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8622 - val_loss: 0.3474 - val_accuracy: 0.8562\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8620 - val_loss: 0.3467 - val_accuracy: 0.8544\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8637 - val_loss: 0.3474 - val_accuracy: 0.8531\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8625 - val_loss: 0.3473 - val_accuracy: 0.8556\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8625 - val_loss: 0.3470 - val_accuracy: 0.8550\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8645 - val_loss: 0.3482 - val_accuracy: 0.8550\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8627 - val_loss: 0.3482 - val_accuracy: 0.8544\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8633 - val_loss: 0.3477 - val_accuracy: 0.8550\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8625 - val_loss: 0.3483 - val_accuracy: 0.8531\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8639 - val_loss: 0.3487 - val_accuracy: 0.8562\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8648 - val_loss: 0.3481 - val_accuracy: 0.8550\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8634 - val_loss: 0.3481 - val_accuracy: 0.8556\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8627 - val_loss: 0.3483 - val_accuracy: 0.8537\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8642 - val_loss: 0.3494 - val_accuracy: 0.8531\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8637 - val_loss: 0.3485 - val_accuracy: 0.8544\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8634 - val_loss: 0.3486 - val_accuracy: 0.8525\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8644 - val_loss: 0.3488 - val_accuracy: 0.8531\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8639 - val_loss: 0.3489 - val_accuracy: 0.8569\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8647 - val_loss: 0.3483 - val_accuracy: 0.8569\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8633 - val_loss: 0.3486 - val_accuracy: 0.8562\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8650 - val_loss: 0.3493 - val_accuracy: 0.8569\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8631 - val_loss: 0.3489 - val_accuracy: 0.8531\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8639 - val_loss: 0.3485 - val_accuracy: 0.8594\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8630 - val_loss: 0.3489 - val_accuracy: 0.8562\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8642 - val_loss: 0.3482 - val_accuracy: 0.8544\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8637 - val_loss: 0.3478 - val_accuracy: 0.8569\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8625 - val_loss: 0.3485 - val_accuracy: 0.8575\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8644 - val_loss: 0.3486 - val_accuracy: 0.8581\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8634 - val_loss: 0.3494 - val_accuracy: 0.8594\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8636 - val_loss: 0.3484 - val_accuracy: 0.8587\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8636 - val_loss: 0.3482 - val_accuracy: 0.8575\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8642 - val_loss: 0.3486 - val_accuracy: 0.8575\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8641 - val_loss: 0.3488 - val_accuracy: 0.8600\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8636 - val_loss: 0.3484 - val_accuracy: 0.8569\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8639 - val_loss: 0.3487 - val_accuracy: 0.8556\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8637 - val_loss: 0.3479 - val_accuracy: 0.8562\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8625 - val_loss: 0.3498 - val_accuracy: 0.8587\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8634 - val_loss: 0.3499 - val_accuracy: 0.8531\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8627 - val_loss: 0.3499 - val_accuracy: 0.8562\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8642 - val_loss: 0.3496 - val_accuracy: 0.8544\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5512 - accuracy: 0.7891 - val_loss: 0.4962 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7934 - val_loss: 0.4591 - val_accuracy: 0.7994\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7945 - val_loss: 0.4383 - val_accuracy: 0.8062\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8025 - val_loss: 0.4249 - val_accuracy: 0.8194\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8072 - val_loss: 0.4167 - val_accuracy: 0.8200\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8119 - val_loss: 0.4083 - val_accuracy: 0.8238\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8225 - val_loss: 0.3999 - val_accuracy: 0.8288\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8291 - val_loss: 0.3911 - val_accuracy: 0.8363\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8369 - val_loss: 0.3810 - val_accuracy: 0.8425\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8445 - val_loss: 0.3737 - val_accuracy: 0.8425\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8508 - val_loss: 0.3665 - val_accuracy: 0.8475\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8527 - val_loss: 0.3596 - val_accuracy: 0.8506\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8559 - val_loss: 0.3556 - val_accuracy: 0.8512\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8567 - val_loss: 0.3516 - val_accuracy: 0.8544\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8573 - val_loss: 0.3485 - val_accuracy: 0.8525\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8595 - val_loss: 0.3467 - val_accuracy: 0.8512\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8580 - val_loss: 0.3448 - val_accuracy: 0.8531\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8602 - val_loss: 0.3455 - val_accuracy: 0.8462\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8614 - val_loss: 0.3436 - val_accuracy: 0.8519\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8603 - val_loss: 0.3445 - val_accuracy: 0.8469\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8612 - val_loss: 0.3451 - val_accuracy: 0.8487\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8628 - val_loss: 0.3431 - val_accuracy: 0.8506\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8630 - val_loss: 0.3407 - val_accuracy: 0.8525\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8631 - val_loss: 0.3401 - val_accuracy: 0.8537\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8645 - val_loss: 0.3421 - val_accuracy: 0.8531\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8641 - val_loss: 0.3412 - val_accuracy: 0.8537\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8633 - val_loss: 0.3402 - val_accuracy: 0.8537\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3341 - accuracy: 0.8642 - val_loss: 0.3401 - val_accuracy: 0.8525\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8619 - val_loss: 0.3392 - val_accuracy: 0.8556\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8648 - val_loss: 0.3399 - val_accuracy: 0.8512\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8631 - val_loss: 0.3403 - val_accuracy: 0.8531\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8650 - val_loss: 0.3392 - val_accuracy: 0.8519\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8656 - val_loss: 0.3386 - val_accuracy: 0.8525\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8650 - val_loss: 0.3389 - val_accuracy: 0.8531\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8630 - val_loss: 0.3379 - val_accuracy: 0.8550\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8634 - val_loss: 0.3373 - val_accuracy: 0.8519\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8641 - val_loss: 0.3383 - val_accuracy: 0.8550\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8656 - val_loss: 0.3378 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8637 - val_loss: 0.3392 - val_accuracy: 0.8544\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8639 - val_loss: 0.3373 - val_accuracy: 0.8556\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8661 - val_loss: 0.3386 - val_accuracy: 0.8544\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8639 - val_loss: 0.3380 - val_accuracy: 0.8556\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8655 - val_loss: 0.3373 - val_accuracy: 0.8537\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8659 - val_loss: 0.3386 - val_accuracy: 0.8550\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8653 - val_loss: 0.3379 - val_accuracy: 0.8569\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8644 - val_loss: 0.3372 - val_accuracy: 0.8537\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8659 - val_loss: 0.3379 - val_accuracy: 0.8550\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8667 - val_loss: 0.3373 - val_accuracy: 0.8569\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8650 - val_loss: 0.3373 - val_accuracy: 0.8544\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8670 - val_loss: 0.3372 - val_accuracy: 0.8562\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8648 - val_loss: 0.3382 - val_accuracy: 0.8550\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8664 - val_loss: 0.3383 - val_accuracy: 0.8544\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8653 - val_loss: 0.3376 - val_accuracy: 0.8550\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8672 - val_loss: 0.3379 - val_accuracy: 0.8562\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8662 - val_loss: 0.3381 - val_accuracy: 0.8575\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8655 - val_loss: 0.3387 - val_accuracy: 0.8544\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8650 - val_loss: 0.3376 - val_accuracy: 0.8550\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8662 - val_loss: 0.3388 - val_accuracy: 0.8562\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8659 - val_loss: 0.3387 - val_accuracy: 0.8556\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8669 - val_loss: 0.3389 - val_accuracy: 0.8556\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8669 - val_loss: 0.3396 - val_accuracy: 0.8537\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8675 - val_loss: 0.3376 - val_accuracy: 0.8569\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8672 - val_loss: 0.3379 - val_accuracy: 0.8575\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8672 - val_loss: 0.3379 - val_accuracy: 0.8562\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8661 - val_loss: 0.3389 - val_accuracy: 0.8581\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8656 - val_loss: 0.3381 - val_accuracy: 0.8550\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8669 - val_loss: 0.3386 - val_accuracy: 0.8594\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8656 - val_loss: 0.3381 - val_accuracy: 0.8581\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8672 - val_loss: 0.3405 - val_accuracy: 0.8500\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8678 - val_loss: 0.3384 - val_accuracy: 0.8556\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8702 - val_loss: 0.3393 - val_accuracy: 0.8562\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8677 - val_loss: 0.3392 - val_accuracy: 0.8544\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8677 - val_loss: 0.3399 - val_accuracy: 0.8587\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8647 - val_loss: 0.3391 - val_accuracy: 0.8544\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8647 - val_loss: 0.3403 - val_accuracy: 0.8562\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8677 - val_loss: 0.3401 - val_accuracy: 0.8569\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8692 - val_loss: 0.3402 - val_accuracy: 0.8587\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8675 - val_loss: 0.3418 - val_accuracy: 0.8569\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8666 - val_loss: 0.3405 - val_accuracy: 0.8562\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8672 - val_loss: 0.3405 - val_accuracy: 0.8606\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8684 - val_loss: 0.3410 - val_accuracy: 0.8581\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8675 - val_loss: 0.3401 - val_accuracy: 0.8569\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8669 - val_loss: 0.3420 - val_accuracy: 0.8525\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8675 - val_loss: 0.3421 - val_accuracy: 0.8562\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8687 - val_loss: 0.3430 - val_accuracy: 0.8594\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8662 - val_loss: 0.3426 - val_accuracy: 0.8587\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8672 - val_loss: 0.3425 - val_accuracy: 0.8581\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8681 - val_loss: 0.3408 - val_accuracy: 0.8544\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8672 - val_loss: 0.3425 - val_accuracy: 0.8531\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8681 - val_loss: 0.3428 - val_accuracy: 0.8550\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8672 - val_loss: 0.3413 - val_accuracy: 0.8600\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8673 - val_loss: 0.3411 - val_accuracy: 0.8569\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8680 - val_loss: 0.3425 - val_accuracy: 0.8606\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8655 - val_loss: 0.3422 - val_accuracy: 0.8581\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8678 - val_loss: 0.3427 - val_accuracy: 0.8556\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8687 - val_loss: 0.3420 - val_accuracy: 0.8594\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8675 - val_loss: 0.3424 - val_accuracy: 0.8594\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8694 - val_loss: 0.3421 - val_accuracy: 0.8544\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8681 - val_loss: 0.3431 - val_accuracy: 0.8531\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8694 - val_loss: 0.3424 - val_accuracy: 0.8587\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 2s 4ms/step - loss: 0.5786 - accuracy: 0.7081 - val_loss: 0.4875 - val_accuracy: 0.7994\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4654 - accuracy: 0.7977 - val_loss: 0.4553 - val_accuracy: 0.8062\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8052 - val_loss: 0.4388 - val_accuracy: 0.8150\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8128 - val_loss: 0.4261 - val_accuracy: 0.8206\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8202 - val_loss: 0.4145 - val_accuracy: 0.8263\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8267 - val_loss: 0.4045 - val_accuracy: 0.8319\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8314 - val_loss: 0.3939 - val_accuracy: 0.8375\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8377 - val_loss: 0.3847 - val_accuracy: 0.8363\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8441 - val_loss: 0.3773 - val_accuracy: 0.8413\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8466 - val_loss: 0.3724 - val_accuracy: 0.8381\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8497 - val_loss: 0.3683 - val_accuracy: 0.8425\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8514 - val_loss: 0.3660 - val_accuracy: 0.8425\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8522 - val_loss: 0.3639 - val_accuracy: 0.8450\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8537 - val_loss: 0.3623 - val_accuracy: 0.8481\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8536 - val_loss: 0.3614 - val_accuracy: 0.8519\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8534 - val_loss: 0.3600 - val_accuracy: 0.8537\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8553 - val_loss: 0.3587 - val_accuracy: 0.8519\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8562 - val_loss: 0.3573 - val_accuracy: 0.8531\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8586 - val_loss: 0.3568 - val_accuracy: 0.8544\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8572 - val_loss: 0.3561 - val_accuracy: 0.8519\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8587 - val_loss: 0.3557 - val_accuracy: 0.8556\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8598 - val_loss: 0.3539 - val_accuracy: 0.8531\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8592 - val_loss: 0.3537 - val_accuracy: 0.8575\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8611 - val_loss: 0.3533 - val_accuracy: 0.8556\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8612 - val_loss: 0.3525 - val_accuracy: 0.8562\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8616 - val_loss: 0.3513 - val_accuracy: 0.8569\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8627 - val_loss: 0.3506 - val_accuracy: 0.8531\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8614 - val_loss: 0.3502 - val_accuracy: 0.8556\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8650 - val_loss: 0.3505 - val_accuracy: 0.8569\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8625 - val_loss: 0.3488 - val_accuracy: 0.8531\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8639 - val_loss: 0.3477 - val_accuracy: 0.8562\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8634 - val_loss: 0.3487 - val_accuracy: 0.8544\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8633 - val_loss: 0.3472 - val_accuracy: 0.8569\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8634 - val_loss: 0.3477 - val_accuracy: 0.8544\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8623 - val_loss: 0.3460 - val_accuracy: 0.8575\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8661 - val_loss: 0.3467 - val_accuracy: 0.8544\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8634 - val_loss: 0.3461 - val_accuracy: 0.8544\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8650 - val_loss: 0.3455 - val_accuracy: 0.8562\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8634 - val_loss: 0.3478 - val_accuracy: 0.8544\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8662 - val_loss: 0.3464 - val_accuracy: 0.8537\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8658 - val_loss: 0.3463 - val_accuracy: 0.8581\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8652 - val_loss: 0.3455 - val_accuracy: 0.8556\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8659 - val_loss: 0.3454 - val_accuracy: 0.8569\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8661 - val_loss: 0.3450 - val_accuracy: 0.8569\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8667 - val_loss: 0.3444 - val_accuracy: 0.8550\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8650 - val_loss: 0.3448 - val_accuracy: 0.8556\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8670 - val_loss: 0.3447 - val_accuracy: 0.8600\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8661 - val_loss: 0.3454 - val_accuracy: 0.8544\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8670 - val_loss: 0.3438 - val_accuracy: 0.8575\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8673 - val_loss: 0.3447 - val_accuracy: 0.8562\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8666 - val_loss: 0.3444 - val_accuracy: 0.8550\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8675 - val_loss: 0.3438 - val_accuracy: 0.8581\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8664 - val_loss: 0.3448 - val_accuracy: 0.8569\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8648 - val_loss: 0.3436 - val_accuracy: 0.8550\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8666 - val_loss: 0.3442 - val_accuracy: 0.8556\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8680 - val_loss: 0.3430 - val_accuracy: 0.8575\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8677 - val_loss: 0.3453 - val_accuracy: 0.8556\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8662 - val_loss: 0.3439 - val_accuracy: 0.8537\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8677 - val_loss: 0.3448 - val_accuracy: 0.8569\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8670 - val_loss: 0.3441 - val_accuracy: 0.8562\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8681 - val_loss: 0.3427 - val_accuracy: 0.8575\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8666 - val_loss: 0.3437 - val_accuracy: 0.8575\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8667 - val_loss: 0.3441 - val_accuracy: 0.8544\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8667 - val_loss: 0.3447 - val_accuracy: 0.8556\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8678 - val_loss: 0.3452 - val_accuracy: 0.8550\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3279 - accuracy: 0.8672 - val_loss: 0.3439 - val_accuracy: 0.8562\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8678 - val_loss: 0.3436 - val_accuracy: 0.8556\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8678 - val_loss: 0.3435 - val_accuracy: 0.8562\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8673 - val_loss: 0.3433 - val_accuracy: 0.8556\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8672 - val_loss: 0.3435 - val_accuracy: 0.8581\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8691 - val_loss: 0.3446 - val_accuracy: 0.8600\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8670 - val_loss: 0.3446 - val_accuracy: 0.8562\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8664 - val_loss: 0.3454 - val_accuracy: 0.8544\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8666 - val_loss: 0.3444 - val_accuracy: 0.8556\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8683 - val_loss: 0.3443 - val_accuracy: 0.8544\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8684 - val_loss: 0.3445 - val_accuracy: 0.8550\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8687 - val_loss: 0.3438 - val_accuracy: 0.8550\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8669 - val_loss: 0.3434 - val_accuracy: 0.8537\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8678 - val_loss: 0.3435 - val_accuracy: 0.8525\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8678 - val_loss: 0.3442 - val_accuracy: 0.8556\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8681 - val_loss: 0.3444 - val_accuracy: 0.8537\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8703 - val_loss: 0.3446 - val_accuracy: 0.8556\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8686 - val_loss: 0.3436 - val_accuracy: 0.8550\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8666 - val_loss: 0.3445 - val_accuracy: 0.8544\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8686 - val_loss: 0.3438 - val_accuracy: 0.8537\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8683 - val_loss: 0.3443 - val_accuracy: 0.8537\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8669 - val_loss: 0.3444 - val_accuracy: 0.8562\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8678 - val_loss: 0.3447 - val_accuracy: 0.8544\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8670 - val_loss: 0.3449 - val_accuracy: 0.8531\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8672 - val_loss: 0.3442 - val_accuracy: 0.8537\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8681 - val_loss: 0.3439 - val_accuracy: 0.8519\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8669 - val_loss: 0.3439 - val_accuracy: 0.8531\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8672 - val_loss: 0.3449 - val_accuracy: 0.8531\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8677 - val_loss: 0.3448 - val_accuracy: 0.8556\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8681 - val_loss: 0.3447 - val_accuracy: 0.8544\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3254 - accuracy: 0.8678 - val_loss: 0.3444 - val_accuracy: 0.8550\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8684 - val_loss: 0.3443 - val_accuracy: 0.8550\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8683 - val_loss: 0.3441 - val_accuracy: 0.8562\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8689 - val_loss: 0.3444 - val_accuracy: 0.8544\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8680 - val_loss: 0.3441 - val_accuracy: 0.8550\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5863 - accuracy: 0.7369 - val_loss: 0.5043 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8012 - val_loss: 0.4353 - val_accuracy: 0.8194\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8208 - val_loss: 0.4221 - val_accuracy: 0.8306\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8250 - val_loss: 0.4175 - val_accuracy: 0.8288\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8308 - val_loss: 0.4124 - val_accuracy: 0.8331\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8319 - val_loss: 0.4084 - val_accuracy: 0.8369\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8352 - val_loss: 0.4037 - val_accuracy: 0.8388\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8353 - val_loss: 0.3980 - val_accuracy: 0.8425\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8400 - val_loss: 0.3898 - val_accuracy: 0.8475\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8452 - val_loss: 0.3810 - val_accuracy: 0.8450\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8492 - val_loss: 0.3743 - val_accuracy: 0.8444\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8562 - val_loss: 0.3667 - val_accuracy: 0.8512\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8566 - val_loss: 0.3622 - val_accuracy: 0.8506\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8609 - val_loss: 0.3598 - val_accuracy: 0.8550\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8589 - val_loss: 0.3584 - val_accuracy: 0.8556\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8583 - val_loss: 0.3573 - val_accuracy: 0.8544\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8619 - val_loss: 0.3555 - val_accuracy: 0.8544\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3437 - accuracy: 0.8598 - val_loss: 0.3546 - val_accuracy: 0.8544\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8597 - val_loss: 0.3539 - val_accuracy: 0.8575\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8616 - val_loss: 0.3525 - val_accuracy: 0.8575\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8612 - val_loss: 0.3527 - val_accuracy: 0.8550\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8636 - val_loss: 0.3559 - val_accuracy: 0.8500\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8622 - val_loss: 0.3512 - val_accuracy: 0.8575\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8620 - val_loss: 0.3509 - val_accuracy: 0.8569\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8603 - val_loss: 0.3503 - val_accuracy: 0.8587\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8605 - val_loss: 0.3499 - val_accuracy: 0.8569\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8623 - val_loss: 0.3498 - val_accuracy: 0.8594\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8630 - val_loss: 0.3526 - val_accuracy: 0.8531\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8631 - val_loss: 0.3507 - val_accuracy: 0.8512\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8620 - val_loss: 0.3497 - val_accuracy: 0.8581\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8628 - val_loss: 0.3495 - val_accuracy: 0.8562\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8620 - val_loss: 0.3486 - val_accuracy: 0.8569\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8625 - val_loss: 0.3489 - val_accuracy: 0.8569\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8630 - val_loss: 0.3484 - val_accuracy: 0.8569\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8636 - val_loss: 0.3483 - val_accuracy: 0.8581\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8630 - val_loss: 0.3501 - val_accuracy: 0.8581\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8633 - val_loss: 0.3488 - val_accuracy: 0.8550\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8623 - val_loss: 0.3478 - val_accuracy: 0.8606\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8627 - val_loss: 0.3487 - val_accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8659 - val_loss: 0.3491 - val_accuracy: 0.8556\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3344 - accuracy: 0.8641 - val_loss: 0.3472 - val_accuracy: 0.8569\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8645 - val_loss: 0.3477 - val_accuracy: 0.8575\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8636 - val_loss: 0.3472 - val_accuracy: 0.8569\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8633 - val_loss: 0.3470 - val_accuracy: 0.8569\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8634 - val_loss: 0.3472 - val_accuracy: 0.8612\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8628 - val_loss: 0.3465 - val_accuracy: 0.8587\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8655 - val_loss: 0.3475 - val_accuracy: 0.8531\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8655 - val_loss: 0.3468 - val_accuracy: 0.8581\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8650 - val_loss: 0.3476 - val_accuracy: 0.8556\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8634 - val_loss: 0.3467 - val_accuracy: 0.8569\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8639 - val_loss: 0.3467 - val_accuracy: 0.8575\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8644 - val_loss: 0.3476 - val_accuracy: 0.8594\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8642 - val_loss: 0.3464 - val_accuracy: 0.8550\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8652 - val_loss: 0.3455 - val_accuracy: 0.8594\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8633 - val_loss: 0.3458 - val_accuracy: 0.8581\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8652 - val_loss: 0.3464 - val_accuracy: 0.8562\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8644 - val_loss: 0.3474 - val_accuracy: 0.8531\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8652 - val_loss: 0.3462 - val_accuracy: 0.8600\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8637 - val_loss: 0.3464 - val_accuracy: 0.8556\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8625 - val_loss: 0.3468 - val_accuracy: 0.8600\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8655 - val_loss: 0.3466 - val_accuracy: 0.8562\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8644 - val_loss: 0.3461 - val_accuracy: 0.8594\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8650 - val_loss: 0.3463 - val_accuracy: 0.8550\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8644 - val_loss: 0.3459 - val_accuracy: 0.8556\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8647 - val_loss: 0.3472 - val_accuracy: 0.8587\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8645 - val_loss: 0.3463 - val_accuracy: 0.8569\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8634 - val_loss: 0.3481 - val_accuracy: 0.8562\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8664 - val_loss: 0.3459 - val_accuracy: 0.8531\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8658 - val_loss: 0.3485 - val_accuracy: 0.8581\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8653 - val_loss: 0.3464 - val_accuracy: 0.8537\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8659 - val_loss: 0.3472 - val_accuracy: 0.8587\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8667 - val_loss: 0.3456 - val_accuracy: 0.8550\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8655 - val_loss: 0.3458 - val_accuracy: 0.8537\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8661 - val_loss: 0.3456 - val_accuracy: 0.8544\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8659 - val_loss: 0.3462 - val_accuracy: 0.8562\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8645 - val_loss: 0.3461 - val_accuracy: 0.8544\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8659 - val_loss: 0.3458 - val_accuracy: 0.8531\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8658 - val_loss: 0.3491 - val_accuracy: 0.8569\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8666 - val_loss: 0.3462 - val_accuracy: 0.8525\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8661 - val_loss: 0.3453 - val_accuracy: 0.8531\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8647 - val_loss: 0.3460 - val_accuracy: 0.8537\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8656 - val_loss: 0.3457 - val_accuracy: 0.8537\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8684 - val_loss: 0.3455 - val_accuracy: 0.8550\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8664 - val_loss: 0.3478 - val_accuracy: 0.8544\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8669 - val_loss: 0.3459 - val_accuracy: 0.8531\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8673 - val_loss: 0.3466 - val_accuracy: 0.8525\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8661 - val_loss: 0.3452 - val_accuracy: 0.8512\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8672 - val_loss: 0.3494 - val_accuracy: 0.8506\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3282 - accuracy: 0.8673 - val_loss: 0.3458 - val_accuracy: 0.8519\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8656 - val_loss: 0.3453 - val_accuracy: 0.8512\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8648 - val_loss: 0.3459 - val_accuracy: 0.8531\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8670 - val_loss: 0.3449 - val_accuracy: 0.8544\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8664 - val_loss: 0.3449 - val_accuracy: 0.8519\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8675 - val_loss: 0.3460 - val_accuracy: 0.8569\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8673 - val_loss: 0.3452 - val_accuracy: 0.8512\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8661 - val_loss: 0.3456 - val_accuracy: 0.8556\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3275 - accuracy: 0.8653 - val_loss: 0.3451 - val_accuracy: 0.8550\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8650 - val_loss: 0.3457 - val_accuracy: 0.8519\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8664 - val_loss: 0.3460 - val_accuracy: 0.8562\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8667 - val_loss: 0.3451 - val_accuracy: 0.8562\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5555 - accuracy: 0.7580 - val_loss: 0.4828 - val_accuracy: 0.7981\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8003 - val_loss: 0.4417 - val_accuracy: 0.8050\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8034 - val_loss: 0.4253 - val_accuracy: 0.8138\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8080 - val_loss: 0.4166 - val_accuracy: 0.8213\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8092 - val_loss: 0.4114 - val_accuracy: 0.8244\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8150 - val_loss: 0.4060 - val_accuracy: 0.8281\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8191 - val_loss: 0.4006 - val_accuracy: 0.8294\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8236 - val_loss: 0.3938 - val_accuracy: 0.8313\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8291 - val_loss: 0.3863 - val_accuracy: 0.8369\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8355 - val_loss: 0.3789 - val_accuracy: 0.8444\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3812 - accuracy: 0.8377 - val_loss: 0.3718 - val_accuracy: 0.8475\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8414 - val_loss: 0.3676 - val_accuracy: 0.8506\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8478 - val_loss: 0.3629 - val_accuracy: 0.8494\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8505 - val_loss: 0.3595 - val_accuracy: 0.8512\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8545 - val_loss: 0.3576 - val_accuracy: 0.8537\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.3522 - accuracy: 0.8558 - val_loss: 0.3553 - val_accuracy: 0.8519\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8562 - val_loss: 0.3553 - val_accuracy: 0.8544\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8584 - val_loss: 0.3529 - val_accuracy: 0.8537\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3465 - accuracy: 0.8591 - val_loss: 0.3539 - val_accuracy: 0.8562\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8567 - val_loss: 0.3520 - val_accuracy: 0.8556\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8586 - val_loss: 0.3518 - val_accuracy: 0.8544\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8578 - val_loss: 0.3544 - val_accuracy: 0.8550\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3426 - accuracy: 0.8595 - val_loss: 0.3505 - val_accuracy: 0.8544\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3420 - accuracy: 0.8584 - val_loss: 0.3514 - val_accuracy: 0.8537\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8578 - val_loss: 0.3500 - val_accuracy: 0.8531\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8595 - val_loss: 0.3496 - val_accuracy: 0.8550\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8589 - val_loss: 0.3504 - val_accuracy: 0.8537\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8603 - val_loss: 0.3491 - val_accuracy: 0.8544\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8594 - val_loss: 0.3485 - val_accuracy: 0.8550\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8591 - val_loss: 0.3491 - val_accuracy: 0.8544\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8611 - val_loss: 0.3485 - val_accuracy: 0.8569\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8602 - val_loss: 0.3471 - val_accuracy: 0.8562\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8605 - val_loss: 0.3480 - val_accuracy: 0.8550\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8606 - val_loss: 0.3459 - val_accuracy: 0.8569\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8606 - val_loss: 0.3459 - val_accuracy: 0.8537\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8617 - val_loss: 0.3447 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8609 - val_loss: 0.3450 - val_accuracy: 0.8594\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8622 - val_loss: 0.3443 - val_accuracy: 0.8587\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8611 - val_loss: 0.3434 - val_accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8631 - val_loss: 0.3424 - val_accuracy: 0.8612\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8627 - val_loss: 0.3422 - val_accuracy: 0.8606\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8630 - val_loss: 0.3432 - val_accuracy: 0.8612\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8620 - val_loss: 0.3416 - val_accuracy: 0.8594\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8648 - val_loss: 0.3415 - val_accuracy: 0.8581\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8650 - val_loss: 0.3411 - val_accuracy: 0.8587\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8631 - val_loss: 0.3403 - val_accuracy: 0.8600\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8650 - val_loss: 0.3420 - val_accuracy: 0.8606\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8650 - val_loss: 0.3400 - val_accuracy: 0.8594\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8647 - val_loss: 0.3402 - val_accuracy: 0.8600\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8642 - val_loss: 0.3405 - val_accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8642 - val_loss: 0.3406 - val_accuracy: 0.8575\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8650 - val_loss: 0.3402 - val_accuracy: 0.8594\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8644 - val_loss: 0.3407 - val_accuracy: 0.8625\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8631 - val_loss: 0.3408 - val_accuracy: 0.8619\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8655 - val_loss: 0.3413 - val_accuracy: 0.8612\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8662 - val_loss: 0.3402 - val_accuracy: 0.8594\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8650 - val_loss: 0.3404 - val_accuracy: 0.8619\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8653 - val_loss: 0.3425 - val_accuracy: 0.8581\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8641 - val_loss: 0.3405 - val_accuracy: 0.8637\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8661 - val_loss: 0.3402 - val_accuracy: 0.8644\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8647 - val_loss: 0.3409 - val_accuracy: 0.8625\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8658 - val_loss: 0.3406 - val_accuracy: 0.8587\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8647 - val_loss: 0.3401 - val_accuracy: 0.8644\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8656 - val_loss: 0.3406 - val_accuracy: 0.8644\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8658 - val_loss: 0.3420 - val_accuracy: 0.8625\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8658 - val_loss: 0.3417 - val_accuracy: 0.8644\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8655 - val_loss: 0.3405 - val_accuracy: 0.8606\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8658 - val_loss: 0.3432 - val_accuracy: 0.8600\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8661 - val_loss: 0.3412 - val_accuracy: 0.8612\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8673 - val_loss: 0.3409 - val_accuracy: 0.8631\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8673 - val_loss: 0.3409 - val_accuracy: 0.8631\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8669 - val_loss: 0.3407 - val_accuracy: 0.8631\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8687 - val_loss: 0.3403 - val_accuracy: 0.8612\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8672 - val_loss: 0.3425 - val_accuracy: 0.8600\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8655 - val_loss: 0.3416 - val_accuracy: 0.8625\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8658 - val_loss: 0.3412 - val_accuracy: 0.8600\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8661 - val_loss: 0.3416 - val_accuracy: 0.8625\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8655 - val_loss: 0.3419 - val_accuracy: 0.8644\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8686 - val_loss: 0.3417 - val_accuracy: 0.8619\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.8653 - val_loss: 0.3430 - val_accuracy: 0.8612\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.8672 - val_loss: 0.3407 - val_accuracy: 0.8625\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8695 - val_loss: 0.3414 - val_accuracy: 0.8587\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8658 - val_loss: 0.3412 - val_accuracy: 0.8606\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8666 - val_loss: 0.3403 - val_accuracy: 0.8625\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3197 - accuracy: 0.8670 - val_loss: 0.3417 - val_accuracy: 0.8625\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8681 - val_loss: 0.3424 - val_accuracy: 0.8644\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3193 - accuracy: 0.8687 - val_loss: 0.3414 - val_accuracy: 0.8625\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8691 - val_loss: 0.3416 - val_accuracy: 0.8631\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8681 - val_loss: 0.3426 - val_accuracy: 0.8669\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8669 - val_loss: 0.3432 - val_accuracy: 0.8625\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3191 - accuracy: 0.8658 - val_loss: 0.3416 - val_accuracy: 0.8637\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8680 - val_loss: 0.3415 - val_accuracy: 0.8606\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8692 - val_loss: 0.3417 - val_accuracy: 0.8612\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8662 - val_loss: 0.3427 - val_accuracy: 0.8637\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8680 - val_loss: 0.3426 - val_accuracy: 0.8637\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8678 - val_loss: 0.3424 - val_accuracy: 0.8631\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8659 - val_loss: 0.3420 - val_accuracy: 0.8650\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8677 - val_loss: 0.3427 - val_accuracy: 0.8637\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8680 - val_loss: 0.3420 - val_accuracy: 0.8619\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8683 - val_loss: 0.3437 - val_accuracy: 0.8669\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5497 - accuracy: 0.7341 - val_loss: 0.4571 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4482 - accuracy: 0.8058 - val_loss: 0.4248 - val_accuracy: 0.8250\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8172 - val_loss: 0.4124 - val_accuracy: 0.8288\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8217 - val_loss: 0.4041 - val_accuracy: 0.8356\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8275 - val_loss: 0.3949 - val_accuracy: 0.8363\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8344 - val_loss: 0.3852 - val_accuracy: 0.8406\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8416 - val_loss: 0.3745 - val_accuracy: 0.8438\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8455 - val_loss: 0.3667 - val_accuracy: 0.8450\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8514 - val_loss: 0.3596 - val_accuracy: 0.8462\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8562 - val_loss: 0.3562 - val_accuracy: 0.8519\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8580 - val_loss: 0.3511 - val_accuracy: 0.8556\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8600 - val_loss: 0.3494 - val_accuracy: 0.8594\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8573 - val_loss: 0.3466 - val_accuracy: 0.8569\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8581 - val_loss: 0.3455 - val_accuracy: 0.8562\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8578 - val_loss: 0.3435 - val_accuracy: 0.8550\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8587 - val_loss: 0.3445 - val_accuracy: 0.8569\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8605 - val_loss: 0.3432 - val_accuracy: 0.8556\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8597 - val_loss: 0.3420 - val_accuracy: 0.8550\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8617 - val_loss: 0.3425 - val_accuracy: 0.8525\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8611 - val_loss: 0.3414 - val_accuracy: 0.8562\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8602 - val_loss: 0.3421 - val_accuracy: 0.8544\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8598 - val_loss: 0.3411 - val_accuracy: 0.8537\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8609 - val_loss: 0.3403 - val_accuracy: 0.8562\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8594 - val_loss: 0.3425 - val_accuracy: 0.8625\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8616 - val_loss: 0.3408 - val_accuracy: 0.8525\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8612 - val_loss: 0.3414 - val_accuracy: 0.8550\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8609 - val_loss: 0.3401 - val_accuracy: 0.8556\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8628 - val_loss: 0.3404 - val_accuracy: 0.8550\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8620 - val_loss: 0.3394 - val_accuracy: 0.8575\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8598 - val_loss: 0.3398 - val_accuracy: 0.8575\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8605 - val_loss: 0.3402 - val_accuracy: 0.8594\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8633 - val_loss: 0.3394 - val_accuracy: 0.8575\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8622 - val_loss: 0.3406 - val_accuracy: 0.8587\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8612 - val_loss: 0.3402 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8630 - val_loss: 0.3404 - val_accuracy: 0.8569\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8609 - val_loss: 0.3402 - val_accuracy: 0.8575\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8611 - val_loss: 0.3397 - val_accuracy: 0.8575\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8614 - val_loss: 0.3400 - val_accuracy: 0.8569\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8627 - val_loss: 0.3394 - val_accuracy: 0.8581\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8603 - val_loss: 0.3403 - val_accuracy: 0.8575\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8622 - val_loss: 0.3396 - val_accuracy: 0.8562\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8628 - val_loss: 0.3398 - val_accuracy: 0.8581\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8616 - val_loss: 0.3412 - val_accuracy: 0.8587\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8627 - val_loss: 0.3388 - val_accuracy: 0.8575\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8622 - val_loss: 0.3398 - val_accuracy: 0.8550\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8620 - val_loss: 0.3381 - val_accuracy: 0.8575\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3297 - accuracy: 0.8628 - val_loss: 0.3390 - val_accuracy: 0.8587\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8623 - val_loss: 0.3386 - val_accuracy: 0.8581\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8634 - val_loss: 0.3379 - val_accuracy: 0.8600\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8634 - val_loss: 0.3396 - val_accuracy: 0.8612\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8620 - val_loss: 0.3397 - val_accuracy: 0.8631\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8628 - val_loss: 0.3408 - val_accuracy: 0.8606\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8625 - val_loss: 0.3393 - val_accuracy: 0.8575\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8628 - val_loss: 0.3381 - val_accuracy: 0.8594\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8623 - val_loss: 0.3412 - val_accuracy: 0.8531\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8614 - val_loss: 0.3380 - val_accuracy: 0.8556\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8616 - val_loss: 0.3380 - val_accuracy: 0.8587\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8622 - val_loss: 0.3388 - val_accuracy: 0.8575\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8627 - val_loss: 0.3382 - val_accuracy: 0.8569\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8622 - val_loss: 0.3390 - val_accuracy: 0.8581\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8652 - val_loss: 0.3385 - val_accuracy: 0.8562\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8614 - val_loss: 0.3377 - val_accuracy: 0.8569\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8633 - val_loss: 0.3394 - val_accuracy: 0.8587\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8634 - val_loss: 0.3394 - val_accuracy: 0.8544\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8619 - val_loss: 0.3393 - val_accuracy: 0.8556\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8630 - val_loss: 0.3400 - val_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8642 - val_loss: 0.3385 - val_accuracy: 0.8562\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8636 - val_loss: 0.3411 - val_accuracy: 0.8531\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8636 - val_loss: 0.3383 - val_accuracy: 0.8550\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8620 - val_loss: 0.3393 - val_accuracy: 0.8562\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8633 - val_loss: 0.3394 - val_accuracy: 0.8556\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8656 - val_loss: 0.3386 - val_accuracy: 0.8600\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8631 - val_loss: 0.3422 - val_accuracy: 0.8625\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8630 - val_loss: 0.3407 - val_accuracy: 0.8537\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8634 - val_loss: 0.3401 - val_accuracy: 0.8575\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8636 - val_loss: 0.3392 - val_accuracy: 0.8587\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8633 - val_loss: 0.3396 - val_accuracy: 0.8594\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8648 - val_loss: 0.3391 - val_accuracy: 0.8550\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8650 - val_loss: 0.3430 - val_accuracy: 0.8619\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8644 - val_loss: 0.3399 - val_accuracy: 0.8562\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8650 - val_loss: 0.3399 - val_accuracy: 0.8587\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8645 - val_loss: 0.3393 - val_accuracy: 0.8537\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8662 - val_loss: 0.3392 - val_accuracy: 0.8587\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8633 - val_loss: 0.3389 - val_accuracy: 0.8569\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8634 - val_loss: 0.3414 - val_accuracy: 0.8525\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8666 - val_loss: 0.3413 - val_accuracy: 0.8519\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8641 - val_loss: 0.3400 - val_accuracy: 0.8619\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8659 - val_loss: 0.3395 - val_accuracy: 0.8556\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8672 - val_loss: 0.3393 - val_accuracy: 0.8562\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8645 - val_loss: 0.3408 - val_accuracy: 0.8606\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8628 - val_loss: 0.3423 - val_accuracy: 0.8612\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8644 - val_loss: 0.3402 - val_accuracy: 0.8575\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3225 - accuracy: 0.8652 - val_loss: 0.3398 - val_accuracy: 0.8569\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8639 - val_loss: 0.3393 - val_accuracy: 0.8612\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8661 - val_loss: 0.3413 - val_accuracy: 0.8606\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3218 - accuracy: 0.8658 - val_loss: 0.3403 - val_accuracy: 0.8587\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8664 - val_loss: 0.3405 - val_accuracy: 0.8569\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8661 - val_loss: 0.3399 - val_accuracy: 0.8531\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8652 - val_loss: 0.3404 - val_accuracy: 0.8525\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8661 - val_loss: 0.3408 - val_accuracy: 0.8612\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5209 - accuracy: 0.7934 - val_loss: 0.4738 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7934 - val_loss: 0.4423 - val_accuracy: 0.7987\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7942 - val_loss: 0.4267 - val_accuracy: 0.8044\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8047 - val_loss: 0.4151 - val_accuracy: 0.8231\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8203 - val_loss: 0.4052 - val_accuracy: 0.8331\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8280 - val_loss: 0.3953 - val_accuracy: 0.8438\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8353 - val_loss: 0.3878 - val_accuracy: 0.8444\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8364 - val_loss: 0.3808 - val_accuracy: 0.8487\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8405 - val_loss: 0.3767 - val_accuracy: 0.8500\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8431 - val_loss: 0.3717 - val_accuracy: 0.8537\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8450 - val_loss: 0.3682 - val_accuracy: 0.8569\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8467 - val_loss: 0.3648 - val_accuracy: 0.8587\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8494 - val_loss: 0.3624 - val_accuracy: 0.8556\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8491 - val_loss: 0.3615 - val_accuracy: 0.8587\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8517 - val_loss: 0.3587 - val_accuracy: 0.8575\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8536 - val_loss: 0.3569 - val_accuracy: 0.8594\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8555 - val_loss: 0.3559 - val_accuracy: 0.8612\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3492 - accuracy: 0.8583 - val_loss: 0.3570 - val_accuracy: 0.8587\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8600 - val_loss: 0.3550 - val_accuracy: 0.8625\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8612 - val_loss: 0.3539 - val_accuracy: 0.8606\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8617 - val_loss: 0.3528 - val_accuracy: 0.8606\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8630 - val_loss: 0.3528 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8636 - val_loss: 0.3525 - val_accuracy: 0.8631\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8625 - val_loss: 0.3528 - val_accuracy: 0.8600\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8642 - val_loss: 0.3528 - val_accuracy: 0.8587\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8644 - val_loss: 0.3525 - val_accuracy: 0.8569\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8655 - val_loss: 0.3532 - val_accuracy: 0.8594\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8641 - val_loss: 0.3529 - val_accuracy: 0.8587\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8642 - val_loss: 0.3505 - val_accuracy: 0.8619\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8653 - val_loss: 0.3520 - val_accuracy: 0.8606\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8631 - val_loss: 0.3507 - val_accuracy: 0.8600\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8639 - val_loss: 0.3517 - val_accuracy: 0.8581\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8666 - val_loss: 0.3504 - val_accuracy: 0.8606\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8669 - val_loss: 0.3508 - val_accuracy: 0.8575\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8661 - val_loss: 0.3510 - val_accuracy: 0.8612\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8661 - val_loss: 0.3511 - val_accuracy: 0.8562\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8664 - val_loss: 0.3521 - val_accuracy: 0.8575\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8681 - val_loss: 0.3515 - val_accuracy: 0.8569\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8684 - val_loss: 0.3511 - val_accuracy: 0.8556\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.8656 - val_loss: 0.3520 - val_accuracy: 0.8575\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3294 - accuracy: 0.8666 - val_loss: 0.3522 - val_accuracy: 0.8575\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8675 - val_loss: 0.3519 - val_accuracy: 0.8581\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8680 - val_loss: 0.3523 - val_accuracy: 0.8556\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8672 - val_loss: 0.3523 - val_accuracy: 0.8550\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8673 - val_loss: 0.3519 - val_accuracy: 0.8550\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8686 - val_loss: 0.3537 - val_accuracy: 0.8569\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8673 - val_loss: 0.3514 - val_accuracy: 0.8519\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8678 - val_loss: 0.3510 - val_accuracy: 0.8537\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8669 - val_loss: 0.3495 - val_accuracy: 0.8544\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8667 - val_loss: 0.3502 - val_accuracy: 0.8494\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8667 - val_loss: 0.3494 - val_accuracy: 0.8569\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8683 - val_loss: 0.3497 - val_accuracy: 0.8587\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8666 - val_loss: 0.3504 - val_accuracy: 0.8550\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8673 - val_loss: 0.3521 - val_accuracy: 0.8494\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8667 - val_loss: 0.3507 - val_accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3203 - accuracy: 0.8680 - val_loss: 0.3510 - val_accuracy: 0.8525\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3198 - accuracy: 0.8698 - val_loss: 0.3507 - val_accuracy: 0.8556\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8692 - val_loss: 0.3523 - val_accuracy: 0.8556\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8697 - val_loss: 0.3519 - val_accuracy: 0.8556\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8681 - val_loss: 0.3523 - val_accuracy: 0.8519\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8675 - val_loss: 0.3522 - val_accuracy: 0.8581\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8692 - val_loss: 0.3532 - val_accuracy: 0.8506\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.8694 - val_loss: 0.3531 - val_accuracy: 0.8556\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8702 - val_loss: 0.3532 - val_accuracy: 0.8562\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8684 - val_loss: 0.3549 - val_accuracy: 0.8581\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8673 - val_loss: 0.3534 - val_accuracy: 0.8550\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8697 - val_loss: 0.3538 - val_accuracy: 0.8500\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8695 - val_loss: 0.3540 - val_accuracy: 0.8544\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8694 - val_loss: 0.3540 - val_accuracy: 0.8544\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8702 - val_loss: 0.3551 - val_accuracy: 0.8562\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.8705 - val_loss: 0.3535 - val_accuracy: 0.8569\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3163 - accuracy: 0.8717 - val_loss: 0.3555 - val_accuracy: 0.8569\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8697 - val_loss: 0.3556 - val_accuracy: 0.8506\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8697 - val_loss: 0.3548 - val_accuracy: 0.8575\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3159 - accuracy: 0.8695 - val_loss: 0.3545 - val_accuracy: 0.8556\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8714 - val_loss: 0.3560 - val_accuracy: 0.8569\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8708 - val_loss: 0.3559 - val_accuracy: 0.8575\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8706 - val_loss: 0.3550 - val_accuracy: 0.8550\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3151 - accuracy: 0.8697 - val_loss: 0.3567 - val_accuracy: 0.8512\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8706 - val_loss: 0.3559 - val_accuracy: 0.8562\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8703 - val_loss: 0.3551 - val_accuracy: 0.8556\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8687 - val_loss: 0.3572 - val_accuracy: 0.8562\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8683 - val_loss: 0.3560 - val_accuracy: 0.8550\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.8694 - val_loss: 0.3572 - val_accuracy: 0.8487\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3137 - accuracy: 0.8703 - val_loss: 0.3570 - val_accuracy: 0.8544\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8716 - val_loss: 0.3579 - val_accuracy: 0.8562\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8714 - val_loss: 0.3592 - val_accuracy: 0.8569\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8714 - val_loss: 0.3588 - val_accuracy: 0.8562\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8706 - val_loss: 0.3575 - val_accuracy: 0.8550\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8711 - val_loss: 0.3568 - val_accuracy: 0.8544\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8698 - val_loss: 0.3578 - val_accuracy: 0.8525\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8698 - val_loss: 0.3579 - val_accuracy: 0.8519\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8708 - val_loss: 0.3569 - val_accuracy: 0.8544\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8706 - val_loss: 0.3570 - val_accuracy: 0.8544\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8714 - val_loss: 0.3569 - val_accuracy: 0.8531\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8691 - val_loss: 0.3584 - val_accuracy: 0.8469\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8692 - val_loss: 0.3575 - val_accuracy: 0.8537\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8702 - val_loss: 0.3576 - val_accuracy: 0.8544\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8703 - val_loss: 0.3588 - val_accuracy: 0.8562\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8703 - val_loss: 0.3587 - val_accuracy: 0.8519\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5123 - accuracy: 0.7933 - val_loss: 0.4571 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7984 - val_loss: 0.4296 - val_accuracy: 0.8156\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8119 - val_loss: 0.4161 - val_accuracy: 0.8300\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8256 - val_loss: 0.4046 - val_accuracy: 0.8325\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8361 - val_loss: 0.3901 - val_accuracy: 0.8425\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8433 - val_loss: 0.3777 - val_accuracy: 0.8425\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8491 - val_loss: 0.3674 - val_accuracy: 0.8487\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8547 - val_loss: 0.3594 - val_accuracy: 0.8506\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8598 - val_loss: 0.3554 - val_accuracy: 0.8556\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8595 - val_loss: 0.3525 - val_accuracy: 0.8500\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8589 - val_loss: 0.3502 - val_accuracy: 0.8544\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8595 - val_loss: 0.3482 - val_accuracy: 0.8556\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8595 - val_loss: 0.3475 - val_accuracy: 0.8537\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8612 - val_loss: 0.3471 - val_accuracy: 0.8562\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8605 - val_loss: 0.3472 - val_accuracy: 0.8531\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8616 - val_loss: 0.3448 - val_accuracy: 0.8512\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8605 - val_loss: 0.3451 - val_accuracy: 0.8556\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8628 - val_loss: 0.3453 - val_accuracy: 0.8550\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8622 - val_loss: 0.3450 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8633 - val_loss: 0.3437 - val_accuracy: 0.8525\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.8628 - val_loss: 0.3441 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8602 - val_loss: 0.3425 - val_accuracy: 0.8531\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8627 - val_loss: 0.3435 - val_accuracy: 0.8537\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8636 - val_loss: 0.3431 - val_accuracy: 0.8512\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8625 - val_loss: 0.3421 - val_accuracy: 0.8531\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8619 - val_loss: 0.3416 - val_accuracy: 0.8512\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8634 - val_loss: 0.3410 - val_accuracy: 0.8519\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8634 - val_loss: 0.3417 - val_accuracy: 0.8500\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8636 - val_loss: 0.3420 - val_accuracy: 0.8531\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8633 - val_loss: 0.3409 - val_accuracy: 0.8500\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8648 - val_loss: 0.3432 - val_accuracy: 0.8537\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8633 - val_loss: 0.3406 - val_accuracy: 0.8519\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8627 - val_loss: 0.3412 - val_accuracy: 0.8531\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8627 - val_loss: 0.3410 - val_accuracy: 0.8512\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8630 - val_loss: 0.3409 - val_accuracy: 0.8537\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8641 - val_loss: 0.3404 - val_accuracy: 0.8500\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8633 - val_loss: 0.3404 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8628 - val_loss: 0.3407 - val_accuracy: 0.8506\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8639 - val_loss: 0.3405 - val_accuracy: 0.8544\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8664 - val_loss: 0.3410 - val_accuracy: 0.8575\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8637 - val_loss: 0.3423 - val_accuracy: 0.8519\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8633 - val_loss: 0.3427 - val_accuracy: 0.8569\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8659 - val_loss: 0.3412 - val_accuracy: 0.8531\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8642 - val_loss: 0.3412 - val_accuracy: 0.8519\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8656 - val_loss: 0.3403 - val_accuracy: 0.8537\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8656 - val_loss: 0.3405 - val_accuracy: 0.8537\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8634 - val_loss: 0.3394 - val_accuracy: 0.8550\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8672 - val_loss: 0.3400 - val_accuracy: 0.8556\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8661 - val_loss: 0.3406 - val_accuracy: 0.8531\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8661 - val_loss: 0.3404 - val_accuracy: 0.8569\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8669 - val_loss: 0.3395 - val_accuracy: 0.8562\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8631 - val_loss: 0.3410 - val_accuracy: 0.8537\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8673 - val_loss: 0.3398 - val_accuracy: 0.8550\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8655 - val_loss: 0.3393 - val_accuracy: 0.8575\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8664 - val_loss: 0.3397 - val_accuracy: 0.8569\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8656 - val_loss: 0.3408 - val_accuracy: 0.8581\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8669 - val_loss: 0.3404 - val_accuracy: 0.8537\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8667 - val_loss: 0.3395 - val_accuracy: 0.8562\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8672 - val_loss: 0.3396 - val_accuracy: 0.8525\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8659 - val_loss: 0.3407 - val_accuracy: 0.8587\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8673 - val_loss: 0.3405 - val_accuracy: 0.8581\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8675 - val_loss: 0.3406 - val_accuracy: 0.8556\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8678 - val_loss: 0.3413 - val_accuracy: 0.8581\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8675 - val_loss: 0.3418 - val_accuracy: 0.8550\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8653 - val_loss: 0.3420 - val_accuracy: 0.8581\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8686 - val_loss: 0.3411 - val_accuracy: 0.8569\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8659 - val_loss: 0.3410 - val_accuracy: 0.8562\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8689 - val_loss: 0.3407 - val_accuracy: 0.8587\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8666 - val_loss: 0.3410 - val_accuracy: 0.8587\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8683 - val_loss: 0.3408 - val_accuracy: 0.8562\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8673 - val_loss: 0.3406 - val_accuracy: 0.8550\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8673 - val_loss: 0.3417 - val_accuracy: 0.8537\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8677 - val_loss: 0.3424 - val_accuracy: 0.8519\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8677 - val_loss: 0.3428 - val_accuracy: 0.8562\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8691 - val_loss: 0.3425 - val_accuracy: 0.8575\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8697 - val_loss: 0.3414 - val_accuracy: 0.8569\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8667 - val_loss: 0.3424 - val_accuracy: 0.8575\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8689 - val_loss: 0.3424 - val_accuracy: 0.8562\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8683 - val_loss: 0.3404 - val_accuracy: 0.8556\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8687 - val_loss: 0.3415 - val_accuracy: 0.8575\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8711 - val_loss: 0.3430 - val_accuracy: 0.8562\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8677 - val_loss: 0.3432 - val_accuracy: 0.8537\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8667 - val_loss: 0.3417 - val_accuracy: 0.8544\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8694 - val_loss: 0.3445 - val_accuracy: 0.8594\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8691 - val_loss: 0.3430 - val_accuracy: 0.8531\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8712 - val_loss: 0.3422 - val_accuracy: 0.8531\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8717 - val_loss: 0.3440 - val_accuracy: 0.8537\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8694 - val_loss: 0.3417 - val_accuracy: 0.8562\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3179 - accuracy: 0.8678 - val_loss: 0.3413 - val_accuracy: 0.8575\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8702 - val_loss: 0.3412 - val_accuracy: 0.8562\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8689 - val_loss: 0.3417 - val_accuracy: 0.8544\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8697 - val_loss: 0.3432 - val_accuracy: 0.8587\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8703 - val_loss: 0.3437 - val_accuracy: 0.8550\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8694 - val_loss: 0.3435 - val_accuracy: 0.8550\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8686 - val_loss: 0.3421 - val_accuracy: 0.8575\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8697 - val_loss: 0.3464 - val_accuracy: 0.8600\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8703 - val_loss: 0.3416 - val_accuracy: 0.8569\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8697 - val_loss: 0.3437 - val_accuracy: 0.8531\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8691 - val_loss: 0.3428 - val_accuracy: 0.8556\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8697 - val_loss: 0.3438 - val_accuracy: 0.8525\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5311 - accuracy: 0.7648 - val_loss: 0.4608 - val_accuracy: 0.8044\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8083 - val_loss: 0.4240 - val_accuracy: 0.8263\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4189 - accuracy: 0.8227 - val_loss: 0.4018 - val_accuracy: 0.8381\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8378 - val_loss: 0.3832 - val_accuracy: 0.8431\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8469 - val_loss: 0.3675 - val_accuracy: 0.8487\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8539 - val_loss: 0.3624 - val_accuracy: 0.8494\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8583 - val_loss: 0.3551 - val_accuracy: 0.8537\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8584 - val_loss: 0.3523 - val_accuracy: 0.8544\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8594 - val_loss: 0.3515 - val_accuracy: 0.8550\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8595 - val_loss: 0.3498 - val_accuracy: 0.8531\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8603 - val_loss: 0.3540 - val_accuracy: 0.8587\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8608 - val_loss: 0.3479 - val_accuracy: 0.8550\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8605 - val_loss: 0.3470 - val_accuracy: 0.8556\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8612 - val_loss: 0.3460 - val_accuracy: 0.8581\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8617 - val_loss: 0.3460 - val_accuracy: 0.8550\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8616 - val_loss: 0.3461 - val_accuracy: 0.8581\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8645 - val_loss: 0.3481 - val_accuracy: 0.8556\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8627 - val_loss: 0.3472 - val_accuracy: 0.8544\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8627 - val_loss: 0.3449 - val_accuracy: 0.8594\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8625 - val_loss: 0.3453 - val_accuracy: 0.8550\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8612 - val_loss: 0.3455 - val_accuracy: 0.8550\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8636 - val_loss: 0.3455 - val_accuracy: 0.8556\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8631 - val_loss: 0.3444 - val_accuracy: 0.8569\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8633 - val_loss: 0.3454 - val_accuracy: 0.8512\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8636 - val_loss: 0.3436 - val_accuracy: 0.8569\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3282 - accuracy: 0.8631 - val_loss: 0.3440 - val_accuracy: 0.8550\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3282 - accuracy: 0.8637 - val_loss: 0.3444 - val_accuracy: 0.8562\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8645 - val_loss: 0.3431 - val_accuracy: 0.8575\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8634 - val_loss: 0.3434 - val_accuracy: 0.8544\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8627 - val_loss: 0.3437 - val_accuracy: 0.8531\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8628 - val_loss: 0.3422 - val_accuracy: 0.8544\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8645 - val_loss: 0.3440 - val_accuracy: 0.8519\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8634 - val_loss: 0.3422 - val_accuracy: 0.8537\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8634 - val_loss: 0.3423 - val_accuracy: 0.8537\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8639 - val_loss: 0.3421 - val_accuracy: 0.8550\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8634 - val_loss: 0.3431 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8661 - val_loss: 0.3442 - val_accuracy: 0.8569\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8653 - val_loss: 0.3412 - val_accuracy: 0.8575\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8636 - val_loss: 0.3428 - val_accuracy: 0.8544\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8658 - val_loss: 0.3430 - val_accuracy: 0.8550\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8650 - val_loss: 0.3434 - val_accuracy: 0.8556\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8652 - val_loss: 0.3426 - val_accuracy: 0.8525\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8648 - val_loss: 0.3425 - val_accuracy: 0.8531\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8647 - val_loss: 0.3442 - val_accuracy: 0.8512\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8659 - val_loss: 0.3411 - val_accuracy: 0.8525\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8659 - val_loss: 0.3416 - val_accuracy: 0.8537\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8644 - val_loss: 0.3444 - val_accuracy: 0.8537\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8652 - val_loss: 0.3424 - val_accuracy: 0.8531\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8666 - val_loss: 0.3420 - val_accuracy: 0.8562\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8664 - val_loss: 0.3423 - val_accuracy: 0.8525\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3206 - accuracy: 0.8667 - val_loss: 0.3416 - val_accuracy: 0.8525\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8659 - val_loss: 0.3428 - val_accuracy: 0.8544\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8639 - val_loss: 0.3430 - val_accuracy: 0.8537\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3206 - accuracy: 0.8659 - val_loss: 0.3420 - val_accuracy: 0.8525\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3195 - accuracy: 0.8667 - val_loss: 0.3421 - val_accuracy: 0.8544\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8653 - val_loss: 0.3421 - val_accuracy: 0.8531\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8650 - val_loss: 0.3420 - val_accuracy: 0.8575\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8658 - val_loss: 0.3412 - val_accuracy: 0.8537\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8673 - val_loss: 0.3423 - val_accuracy: 0.8525\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8675 - val_loss: 0.3429 - val_accuracy: 0.8544\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8667 - val_loss: 0.3428 - val_accuracy: 0.8525\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8658 - val_loss: 0.3428 - val_accuracy: 0.8512\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8664 - val_loss: 0.3450 - val_accuracy: 0.8531\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8669 - val_loss: 0.3422 - val_accuracy: 0.8525\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8661 - val_loss: 0.3443 - val_accuracy: 0.8537\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8669 - val_loss: 0.3430 - val_accuracy: 0.8537\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8673 - val_loss: 0.3447 - val_accuracy: 0.8525\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8677 - val_loss: 0.3436 - val_accuracy: 0.8525\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8675 - val_loss: 0.3440 - val_accuracy: 0.8531\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8681 - val_loss: 0.3434 - val_accuracy: 0.8544\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8661 - val_loss: 0.3432 - val_accuracy: 0.8537\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8672 - val_loss: 0.3448 - val_accuracy: 0.8525\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8672 - val_loss: 0.3440 - val_accuracy: 0.8506\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8648 - val_loss: 0.3429 - val_accuracy: 0.8531\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.8675 - val_loss: 0.3445 - val_accuracy: 0.8531\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8694 - val_loss: 0.3444 - val_accuracy: 0.8525\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8666 - val_loss: 0.3443 - val_accuracy: 0.8544\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8667 - val_loss: 0.3434 - val_accuracy: 0.8531\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8695 - val_loss: 0.3430 - val_accuracy: 0.8519\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8680 - val_loss: 0.3428 - val_accuracy: 0.8519\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8681 - val_loss: 0.3449 - val_accuracy: 0.8531\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8689 - val_loss: 0.3441 - val_accuracy: 0.8525\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8705 - val_loss: 0.3446 - val_accuracy: 0.8537\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8697 - val_loss: 0.3454 - val_accuracy: 0.8525\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8694 - val_loss: 0.3435 - val_accuracy: 0.8519\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8692 - val_loss: 0.3454 - val_accuracy: 0.8544\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8684 - val_loss: 0.3444 - val_accuracy: 0.8537\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8691 - val_loss: 0.3462 - val_accuracy: 0.8512\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8689 - val_loss: 0.3474 - val_accuracy: 0.8537\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8678 - val_loss: 0.3459 - val_accuracy: 0.8494\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8694 - val_loss: 0.3439 - val_accuracy: 0.8544\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8700 - val_loss: 0.3452 - val_accuracy: 0.8556\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8694 - val_loss: 0.3476 - val_accuracy: 0.8550\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8700 - val_loss: 0.3473 - val_accuracy: 0.8512\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8691 - val_loss: 0.3451 - val_accuracy: 0.8525\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8702 - val_loss: 0.3459 - val_accuracy: 0.8506\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8698 - val_loss: 0.3461 - val_accuracy: 0.8531\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8683 - val_loss: 0.3467 - val_accuracy: 0.8525\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8691 - val_loss: 0.3453 - val_accuracy: 0.8506\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8698 - val_loss: 0.3468 - val_accuracy: 0.8537\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5061 - accuracy: 0.7836 - val_loss: 0.4483 - val_accuracy: 0.8019\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8062 - val_loss: 0.4088 - val_accuracy: 0.8294\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8267 - val_loss: 0.3912 - val_accuracy: 0.8413\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8413 - val_loss: 0.3778 - val_accuracy: 0.8400\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8495 - val_loss: 0.3698 - val_accuracy: 0.8469\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8523 - val_loss: 0.3615 - val_accuracy: 0.8512\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8586 - val_loss: 0.3592 - val_accuracy: 0.8500\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8589 - val_loss: 0.3552 - val_accuracy: 0.8544\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8605 - val_loss: 0.3530 - val_accuracy: 0.8556\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8589 - val_loss: 0.3514 - val_accuracy: 0.8544\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8598 - val_loss: 0.3514 - val_accuracy: 0.8550\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8602 - val_loss: 0.3522 - val_accuracy: 0.8531\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8611 - val_loss: 0.3499 - val_accuracy: 0.8519\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8620 - val_loss: 0.3486 - val_accuracy: 0.8556\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8636 - val_loss: 0.3490 - val_accuracy: 0.8544\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8627 - val_loss: 0.3481 - val_accuracy: 0.8537\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8627 - val_loss: 0.3489 - val_accuracy: 0.8519\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8637 - val_loss: 0.3488 - val_accuracy: 0.8531\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8642 - val_loss: 0.3461 - val_accuracy: 0.8556\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8637 - val_loss: 0.3464 - val_accuracy: 0.8562\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8641 - val_loss: 0.3463 - val_accuracy: 0.8556\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8645 - val_loss: 0.3464 - val_accuracy: 0.8550\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8637 - val_loss: 0.3465 - val_accuracy: 0.8569\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8645 - val_loss: 0.3466 - val_accuracy: 0.8556\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8650 - val_loss: 0.3472 - val_accuracy: 0.8544\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8641 - val_loss: 0.3473 - val_accuracy: 0.8550\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8659 - val_loss: 0.3453 - val_accuracy: 0.8562\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8650 - val_loss: 0.3465 - val_accuracy: 0.8575\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8650 - val_loss: 0.3464 - val_accuracy: 0.8531\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8655 - val_loss: 0.3452 - val_accuracy: 0.8556\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8636 - val_loss: 0.3452 - val_accuracy: 0.8569\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8656 - val_loss: 0.3462 - val_accuracy: 0.8594\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8642 - val_loss: 0.3458 - val_accuracy: 0.8587\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8650 - val_loss: 0.3471 - val_accuracy: 0.8569\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8667 - val_loss: 0.3467 - val_accuracy: 0.8575\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8652 - val_loss: 0.3474 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8647 - val_loss: 0.3464 - val_accuracy: 0.8556\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8645 - val_loss: 0.3478 - val_accuracy: 0.8537\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8667 - val_loss: 0.3492 - val_accuracy: 0.8531\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8652 - val_loss: 0.3481 - val_accuracy: 0.8531\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8670 - val_loss: 0.3490 - val_accuracy: 0.8594\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8677 - val_loss: 0.3492 - val_accuracy: 0.8594\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8670 - val_loss: 0.3498 - val_accuracy: 0.8537\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8659 - val_loss: 0.3488 - val_accuracy: 0.8537\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8656 - val_loss: 0.3491 - val_accuracy: 0.8525\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8653 - val_loss: 0.3492 - val_accuracy: 0.8537\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8677 - val_loss: 0.3505 - val_accuracy: 0.8525\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8672 - val_loss: 0.3487 - val_accuracy: 0.8562\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8664 - val_loss: 0.3487 - val_accuracy: 0.8575\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8645 - val_loss: 0.3500 - val_accuracy: 0.8556\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8655 - val_loss: 0.3484 - val_accuracy: 0.8550\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8652 - val_loss: 0.3493 - val_accuracy: 0.8562\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8647 - val_loss: 0.3491 - val_accuracy: 0.8550\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8658 - val_loss: 0.3505 - val_accuracy: 0.8569\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8664 - val_loss: 0.3501 - val_accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8684 - val_loss: 0.3515 - val_accuracy: 0.8537\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8669 - val_loss: 0.3540 - val_accuracy: 0.8575\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8669 - val_loss: 0.3521 - val_accuracy: 0.8569\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8681 - val_loss: 0.3551 - val_accuracy: 0.8587\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8666 - val_loss: 0.3502 - val_accuracy: 0.8562\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8650 - val_loss: 0.3501 - val_accuracy: 0.8544\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8667 - val_loss: 0.3508 - val_accuracy: 0.8537\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8667 - val_loss: 0.3504 - val_accuracy: 0.8519\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8677 - val_loss: 0.3503 - val_accuracy: 0.8562\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8673 - val_loss: 0.3526 - val_accuracy: 0.8581\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8648 - val_loss: 0.3536 - val_accuracy: 0.8587\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8666 - val_loss: 0.3519 - val_accuracy: 0.8531\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8645 - val_loss: 0.3508 - val_accuracy: 0.8544\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8664 - val_loss: 0.3512 - val_accuracy: 0.8562\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8673 - val_loss: 0.3527 - val_accuracy: 0.8581\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8667 - val_loss: 0.3518 - val_accuracy: 0.8550\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8652 - val_loss: 0.3529 - val_accuracy: 0.8537\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8658 - val_loss: 0.3537 - val_accuracy: 0.8600\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8662 - val_loss: 0.3529 - val_accuracy: 0.8544\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8673 - val_loss: 0.3533 - val_accuracy: 0.8544\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8664 - val_loss: 0.3533 - val_accuracy: 0.8475\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8673 - val_loss: 0.3535 - val_accuracy: 0.8500\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8667 - val_loss: 0.3543 - val_accuracy: 0.8544\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8666 - val_loss: 0.3563 - val_accuracy: 0.8562\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8670 - val_loss: 0.3566 - val_accuracy: 0.8562\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8667 - val_loss: 0.3543 - val_accuracy: 0.8544\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8673 - val_loss: 0.3590 - val_accuracy: 0.8569\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8666 - val_loss: 0.3538 - val_accuracy: 0.8531\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8666 - val_loss: 0.3547 - val_accuracy: 0.8562\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8658 - val_loss: 0.3555 - val_accuracy: 0.8531\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8678 - val_loss: 0.3584 - val_accuracy: 0.8581\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8670 - val_loss: 0.3577 - val_accuracy: 0.8569\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8662 - val_loss: 0.3558 - val_accuracy: 0.8537\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8686 - val_loss: 0.3569 - val_accuracy: 0.8556\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8666 - val_loss: 0.3570 - val_accuracy: 0.8550\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8667 - val_loss: 0.3573 - val_accuracy: 0.8500\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8686 - val_loss: 0.3575 - val_accuracy: 0.8544\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8686 - val_loss: 0.3577 - val_accuracy: 0.8469\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8694 - val_loss: 0.3583 - val_accuracy: 0.8569\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8689 - val_loss: 0.3569 - val_accuracy: 0.8512\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8684 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8667 - val_loss: 0.3578 - val_accuracy: 0.8500\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8686 - val_loss: 0.3578 - val_accuracy: 0.8562\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3089 - accuracy: 0.8669 - val_loss: 0.3585 - val_accuracy: 0.8550\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3092 - accuracy: 0.8681 - val_loss: 0.3564 - val_accuracy: 0.8544\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5118 - accuracy: 0.7725 - val_loss: 0.4432 - val_accuracy: 0.8081\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8116 - val_loss: 0.4092 - val_accuracy: 0.8294\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8355 - val_loss: 0.3867 - val_accuracy: 0.8406\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8486 - val_loss: 0.3698 - val_accuracy: 0.8506\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8548 - val_loss: 0.3609 - val_accuracy: 0.8537\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8564 - val_loss: 0.3553 - val_accuracy: 0.8525\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8594 - val_loss: 0.3509 - val_accuracy: 0.8569\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8594 - val_loss: 0.3501 - val_accuracy: 0.8544\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8587 - val_loss: 0.3474 - val_accuracy: 0.8562\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8631 - val_loss: 0.3466 - val_accuracy: 0.8569\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8614 - val_loss: 0.3453 - val_accuracy: 0.8575\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8627 - val_loss: 0.3455 - val_accuracy: 0.8550\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8625 - val_loss: 0.3462 - val_accuracy: 0.8569\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8623 - val_loss: 0.3428 - val_accuracy: 0.8537\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8631 - val_loss: 0.3425 - val_accuracy: 0.8575\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8652 - val_loss: 0.3499 - val_accuracy: 0.8569\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8650 - val_loss: 0.3475 - val_accuracy: 0.8600\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8642 - val_loss: 0.3427 - val_accuracy: 0.8575\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8667 - val_loss: 0.3422 - val_accuracy: 0.8594\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8683 - val_loss: 0.3420 - val_accuracy: 0.8550\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8669 - val_loss: 0.3421 - val_accuracy: 0.8550\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8677 - val_loss: 0.3419 - val_accuracy: 0.8575\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8666 - val_loss: 0.3435 - val_accuracy: 0.8575\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8666 - val_loss: 0.3426 - val_accuracy: 0.8544\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8672 - val_loss: 0.3432 - val_accuracy: 0.8537\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3258 - accuracy: 0.8694 - val_loss: 0.3414 - val_accuracy: 0.8550\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8662 - val_loss: 0.3419 - val_accuracy: 0.8544\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8673 - val_loss: 0.3421 - val_accuracy: 0.8562\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8662 - val_loss: 0.3407 - val_accuracy: 0.8531\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8662 - val_loss: 0.3421 - val_accuracy: 0.8531\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8658 - val_loss: 0.3414 - val_accuracy: 0.8525\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8678 - val_loss: 0.3414 - val_accuracy: 0.8537\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8697 - val_loss: 0.3418 - val_accuracy: 0.8525\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8692 - val_loss: 0.3399 - val_accuracy: 0.8544\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8681 - val_loss: 0.3416 - val_accuracy: 0.8544\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8698 - val_loss: 0.3413 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8691 - val_loss: 0.3418 - val_accuracy: 0.8562\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8673 - val_loss: 0.3416 - val_accuracy: 0.8531\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8691 - val_loss: 0.3428 - val_accuracy: 0.8531\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8684 - val_loss: 0.3428 - val_accuracy: 0.8506\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8686 - val_loss: 0.3413 - val_accuracy: 0.8537\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8694 - val_loss: 0.3424 - val_accuracy: 0.8531\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8680 - val_loss: 0.3422 - val_accuracy: 0.8512\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8706 - val_loss: 0.3419 - val_accuracy: 0.8494\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8691 - val_loss: 0.3431 - val_accuracy: 0.8475\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8698 - val_loss: 0.3426 - val_accuracy: 0.8512\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8702 - val_loss: 0.3415 - val_accuracy: 0.8525\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8705 - val_loss: 0.3419 - val_accuracy: 0.8525\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8695 - val_loss: 0.3458 - val_accuracy: 0.8500\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.8717 - val_loss: 0.3434 - val_accuracy: 0.8481\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8711 - val_loss: 0.3433 - val_accuracy: 0.8512\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8712 - val_loss: 0.3445 - val_accuracy: 0.8512\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8719 - val_loss: 0.3450 - val_accuracy: 0.8487\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8702 - val_loss: 0.3450 - val_accuracy: 0.8506\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8727 - val_loss: 0.3438 - val_accuracy: 0.8544\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8697 - val_loss: 0.3454 - val_accuracy: 0.8525\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8722 - val_loss: 0.3461 - val_accuracy: 0.8469\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8700 - val_loss: 0.3448 - val_accuracy: 0.8525\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8708 - val_loss: 0.3448 - val_accuracy: 0.8512\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8703 - val_loss: 0.3445 - val_accuracy: 0.8481\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8708 - val_loss: 0.3450 - val_accuracy: 0.8462\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8705 - val_loss: 0.3452 - val_accuracy: 0.8519\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8727 - val_loss: 0.3461 - val_accuracy: 0.8487\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8733 - val_loss: 0.3458 - val_accuracy: 0.8537\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8737 - val_loss: 0.3463 - val_accuracy: 0.8494\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3111 - accuracy: 0.8720 - val_loss: 0.3481 - val_accuracy: 0.8494\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.3120 - accuracy: 0.8736 - val_loss: 0.3456 - val_accuracy: 0.8494\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8717 - val_loss: 0.3468 - val_accuracy: 0.8500\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8725 - val_loss: 0.3462 - val_accuracy: 0.8481\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8725 - val_loss: 0.3473 - val_accuracy: 0.8487\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8720 - val_loss: 0.3466 - val_accuracy: 0.8475\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8728 - val_loss: 0.3474 - val_accuracy: 0.8487\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8711 - val_loss: 0.3454 - val_accuracy: 0.8494\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.8709 - val_loss: 0.3476 - val_accuracy: 0.8506\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.3101 - accuracy: 0.8733 - val_loss: 0.3475 - val_accuracy: 0.8481\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.8737 - val_loss: 0.3470 - val_accuracy: 0.8450\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.8730 - val_loss: 0.3466 - val_accuracy: 0.8500\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8709 - val_loss: 0.3475 - val_accuracy: 0.8469\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8717 - val_loss: 0.3511 - val_accuracy: 0.8481\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8728 - val_loss: 0.3469 - val_accuracy: 0.8481\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8750 - val_loss: 0.3481 - val_accuracy: 0.8425\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8727 - val_loss: 0.3464 - val_accuracy: 0.8462\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8731 - val_loss: 0.3480 - val_accuracy: 0.8481\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8730 - val_loss: 0.3476 - val_accuracy: 0.8512\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8742 - val_loss: 0.3464 - val_accuracy: 0.8475\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8723 - val_loss: 0.3491 - val_accuracy: 0.8500\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8744 - val_loss: 0.3516 - val_accuracy: 0.8438\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8720 - val_loss: 0.3484 - val_accuracy: 0.8431\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8748 - val_loss: 0.3503 - val_accuracy: 0.8494\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8723 - val_loss: 0.3503 - val_accuracy: 0.8487\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8728 - val_loss: 0.3497 - val_accuracy: 0.8531\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8731 - val_loss: 0.3482 - val_accuracy: 0.8487\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8747 - val_loss: 0.3487 - val_accuracy: 0.8438\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8734 - val_loss: 0.3487 - val_accuracy: 0.8456\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8730 - val_loss: 0.3495 - val_accuracy: 0.8469\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3066 - accuracy: 0.8742 - val_loss: 0.3491 - val_accuracy: 0.8481\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8731 - val_loss: 0.3493 - val_accuracy: 0.8481\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8736 - val_loss: 0.3509 - val_accuracy: 0.8487\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8727 - val_loss: 0.3493 - val_accuracy: 0.8431\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8739 - val_loss: 0.3498 - val_accuracy: 0.8481\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5497 - accuracy: 0.7481 - val_loss: 0.4526 - val_accuracy: 0.8138\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8102 - val_loss: 0.4187 - val_accuracy: 0.8181\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8166 - val_loss: 0.4086 - val_accuracy: 0.8219\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8241 - val_loss: 0.3967 - val_accuracy: 0.8319\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8359 - val_loss: 0.3814 - val_accuracy: 0.8425\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8458 - val_loss: 0.3700 - val_accuracy: 0.8469\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8520 - val_loss: 0.3630 - val_accuracy: 0.8531\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8520 - val_loss: 0.3576 - val_accuracy: 0.8519\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8569 - val_loss: 0.3591 - val_accuracy: 0.8544\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8564 - val_loss: 0.3559 - val_accuracy: 0.8512\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8556 - val_loss: 0.3555 - val_accuracy: 0.8531\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8572 - val_loss: 0.3535 - val_accuracy: 0.8550\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8567 - val_loss: 0.3525 - val_accuracy: 0.8556\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8587 - val_loss: 0.3509 - val_accuracy: 0.8556\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8586 - val_loss: 0.3519 - val_accuracy: 0.8537\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8591 - val_loss: 0.3497 - val_accuracy: 0.8569\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8583 - val_loss: 0.3506 - val_accuracy: 0.8544\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8584 - val_loss: 0.3492 - val_accuracy: 0.8612\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3394 - accuracy: 0.8595 - val_loss: 0.3502 - val_accuracy: 0.8575\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8609 - val_loss: 0.3472 - val_accuracy: 0.8606\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8617 - val_loss: 0.3469 - val_accuracy: 0.8594\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8619 - val_loss: 0.3472 - val_accuracy: 0.8569\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8603 - val_loss: 0.3457 - val_accuracy: 0.8550\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8603 - val_loss: 0.3460 - val_accuracy: 0.8625\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8605 - val_loss: 0.3452 - val_accuracy: 0.8637\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8611 - val_loss: 0.3482 - val_accuracy: 0.8612\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8631 - val_loss: 0.3460 - val_accuracy: 0.8637\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8614 - val_loss: 0.3436 - val_accuracy: 0.8575\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8650 - val_loss: 0.3446 - val_accuracy: 0.8600\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8650 - val_loss: 0.3446 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3286 - accuracy: 0.8634 - val_loss: 0.3457 - val_accuracy: 0.8544\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8639 - val_loss: 0.3438 - val_accuracy: 0.8575\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8647 - val_loss: 0.3440 - val_accuracy: 0.8544\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8642 - val_loss: 0.3460 - val_accuracy: 0.8612\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8637 - val_loss: 0.3437 - val_accuracy: 0.8587\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8673 - val_loss: 0.3449 - val_accuracy: 0.8587\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8684 - val_loss: 0.3425 - val_accuracy: 0.8587\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8669 - val_loss: 0.3467 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8662 - val_loss: 0.3430 - val_accuracy: 0.8556\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8680 - val_loss: 0.3450 - val_accuracy: 0.8569\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8673 - val_loss: 0.3431 - val_accuracy: 0.8606\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8675 - val_loss: 0.3432 - val_accuracy: 0.8569\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8680 - val_loss: 0.3459 - val_accuracy: 0.8600\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8669 - val_loss: 0.3432 - val_accuracy: 0.8600\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8673 - val_loss: 0.3436 - val_accuracy: 0.8619\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8686 - val_loss: 0.3443 - val_accuracy: 0.8625\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8698 - val_loss: 0.3423 - val_accuracy: 0.8619\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8694 - val_loss: 0.3442 - val_accuracy: 0.8600\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8691 - val_loss: 0.3438 - val_accuracy: 0.8612\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8680 - val_loss: 0.3431 - val_accuracy: 0.8619\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8706 - val_loss: 0.3458 - val_accuracy: 0.8606\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8698 - val_loss: 0.3448 - val_accuracy: 0.8637\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8700 - val_loss: 0.3475 - val_accuracy: 0.8569\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8697 - val_loss: 0.3452 - val_accuracy: 0.8594\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8706 - val_loss: 0.3460 - val_accuracy: 0.8612\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8683 - val_loss: 0.3445 - val_accuracy: 0.8587\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8703 - val_loss: 0.3469 - val_accuracy: 0.8575\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8711 - val_loss: 0.3467 - val_accuracy: 0.8600\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8703 - val_loss: 0.3457 - val_accuracy: 0.8625\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8689 - val_loss: 0.3455 - val_accuracy: 0.8606\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8712 - val_loss: 0.3488 - val_accuracy: 0.8600\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8703 - val_loss: 0.3459 - val_accuracy: 0.8644\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8691 - val_loss: 0.3452 - val_accuracy: 0.8575\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8702 - val_loss: 0.3457 - val_accuracy: 0.8587\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8709 - val_loss: 0.3454 - val_accuracy: 0.8569\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3123 - accuracy: 0.8697 - val_loss: 0.3452 - val_accuracy: 0.8606\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8708 - val_loss: 0.3460 - val_accuracy: 0.8587\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8728 - val_loss: 0.3495 - val_accuracy: 0.8600\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8712 - val_loss: 0.3489 - val_accuracy: 0.8575\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8694 - val_loss: 0.3451 - val_accuracy: 0.8556\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8694 - val_loss: 0.3477 - val_accuracy: 0.8581\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8709 - val_loss: 0.3472 - val_accuracy: 0.8575\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8716 - val_loss: 0.3464 - val_accuracy: 0.8581\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8717 - val_loss: 0.3457 - val_accuracy: 0.8600\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8698 - val_loss: 0.3469 - val_accuracy: 0.8575\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8711 - val_loss: 0.3466 - val_accuracy: 0.8587\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8711 - val_loss: 0.3486 - val_accuracy: 0.8575\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8714 - val_loss: 0.3474 - val_accuracy: 0.8544\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8698 - val_loss: 0.3475 - val_accuracy: 0.8550\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8722 - val_loss: 0.3486 - val_accuracy: 0.8637\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8720 - val_loss: 0.3514 - val_accuracy: 0.8587\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3088 - accuracy: 0.8709 - val_loss: 0.3486 - val_accuracy: 0.8575\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8722 - val_loss: 0.3489 - val_accuracy: 0.8594\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8687 - val_loss: 0.3484 - val_accuracy: 0.8600\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8728 - val_loss: 0.3484 - val_accuracy: 0.8550\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8714 - val_loss: 0.3504 - val_accuracy: 0.8575\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8708 - val_loss: 0.3528 - val_accuracy: 0.8562\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8717 - val_loss: 0.3500 - val_accuracy: 0.8587\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8708 - val_loss: 0.3521 - val_accuracy: 0.8612\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3086 - accuracy: 0.8703 - val_loss: 0.3501 - val_accuracy: 0.8600\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8725 - val_loss: 0.3502 - val_accuracy: 0.8587\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8706 - val_loss: 0.3560 - val_accuracy: 0.8550\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8719 - val_loss: 0.3518 - val_accuracy: 0.8556\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8722 - val_loss: 0.3509 - val_accuracy: 0.8594\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8697 - val_loss: 0.3516 - val_accuracy: 0.8569\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3073 - accuracy: 0.8716 - val_loss: 0.3507 - val_accuracy: 0.8587\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3068 - accuracy: 0.8705 - val_loss: 0.3561 - val_accuracy: 0.8531\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3062 - accuracy: 0.8734 - val_loss: 0.3521 - val_accuracy: 0.8587\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8712 - val_loss: 0.3504 - val_accuracy: 0.8587\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8703 - val_loss: 0.3501 - val_accuracy: 0.8587\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.6350 - val_loss: 0.4681 - val_accuracy: 0.8050\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8028 - val_loss: 0.4177 - val_accuracy: 0.8231\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8216 - val_loss: 0.4019 - val_accuracy: 0.8363\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8327 - val_loss: 0.3845 - val_accuracy: 0.8431\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8452 - val_loss: 0.3674 - val_accuracy: 0.8512\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8519 - val_loss: 0.3589 - val_accuracy: 0.8506\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3512 - accuracy: 0.8561 - val_loss: 0.3539 - val_accuracy: 0.8506\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8573 - val_loss: 0.3513 - val_accuracy: 0.8531\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8577 - val_loss: 0.3502 - val_accuracy: 0.8544\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8594 - val_loss: 0.3494 - val_accuracy: 0.8487\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8597 - val_loss: 0.3484 - val_accuracy: 0.8506\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8595 - val_loss: 0.3476 - val_accuracy: 0.8512\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8598 - val_loss: 0.3467 - val_accuracy: 0.8537\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8612 - val_loss: 0.3471 - val_accuracy: 0.8581\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8622 - val_loss: 0.3452 - val_accuracy: 0.8525\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8623 - val_loss: 0.3460 - val_accuracy: 0.8494\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8628 - val_loss: 0.3449 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8637 - val_loss: 0.3441 - val_accuracy: 0.8475\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8645 - val_loss: 0.3436 - val_accuracy: 0.8506\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8633 - val_loss: 0.3437 - val_accuracy: 0.8550\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8628 - val_loss: 0.3437 - val_accuracy: 0.8494\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8661 - val_loss: 0.3424 - val_accuracy: 0.8519\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8659 - val_loss: 0.3441 - val_accuracy: 0.8512\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8653 - val_loss: 0.3426 - val_accuracy: 0.8506\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8641 - val_loss: 0.3423 - val_accuracy: 0.8531\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8672 - val_loss: 0.3433 - val_accuracy: 0.8550\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8673 - val_loss: 0.3422 - val_accuracy: 0.8562\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8689 - val_loss: 0.3416 - val_accuracy: 0.8537\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8697 - val_loss: 0.3451 - val_accuracy: 0.8556\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8702 - val_loss: 0.3444 - val_accuracy: 0.8556\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.8689 - val_loss: 0.3426 - val_accuracy: 0.8531\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8695 - val_loss: 0.3423 - val_accuracy: 0.8519\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8677 - val_loss: 0.3417 - val_accuracy: 0.8550\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8686 - val_loss: 0.3419 - val_accuracy: 0.8550\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8698 - val_loss: 0.3413 - val_accuracy: 0.8512\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8695 - val_loss: 0.3427 - val_accuracy: 0.8556\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8703 - val_loss: 0.3450 - val_accuracy: 0.8575\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8700 - val_loss: 0.3453 - val_accuracy: 0.8537\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8691 - val_loss: 0.3425 - val_accuracy: 0.8569\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8722 - val_loss: 0.3426 - val_accuracy: 0.8569\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8717 - val_loss: 0.3421 - val_accuracy: 0.8544\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8700 - val_loss: 0.3435 - val_accuracy: 0.8550\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8719 - val_loss: 0.3430 - val_accuracy: 0.8569\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8733 - val_loss: 0.3438 - val_accuracy: 0.8569\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8709 - val_loss: 0.3432 - val_accuracy: 0.8506\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3135 - accuracy: 0.8695 - val_loss: 0.3428 - val_accuracy: 0.8581\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8706 - val_loss: 0.3451 - val_accuracy: 0.8531\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8711 - val_loss: 0.3441 - val_accuracy: 0.8550\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8714 - val_loss: 0.3441 - val_accuracy: 0.8562\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8706 - val_loss: 0.3450 - val_accuracy: 0.8600\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8706 - val_loss: 0.3455 - val_accuracy: 0.8575\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8714 - val_loss: 0.3462 - val_accuracy: 0.8569\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3105 - accuracy: 0.8731 - val_loss: 0.3449 - val_accuracy: 0.8575\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3109 - accuracy: 0.8712 - val_loss: 0.3463 - val_accuracy: 0.8594\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8714 - val_loss: 0.3494 - val_accuracy: 0.8562\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8714 - val_loss: 0.3480 - val_accuracy: 0.8550\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8717 - val_loss: 0.3477 - val_accuracy: 0.8562\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8717 - val_loss: 0.3469 - val_accuracy: 0.8562\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8714 - val_loss: 0.3490 - val_accuracy: 0.8544\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8714 - val_loss: 0.3478 - val_accuracy: 0.8569\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8711 - val_loss: 0.3474 - val_accuracy: 0.8562\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8736 - val_loss: 0.3482 - val_accuracy: 0.8544\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8723 - val_loss: 0.3493 - val_accuracy: 0.8550\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3075 - accuracy: 0.8725 - val_loss: 0.3481 - val_accuracy: 0.8562\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8739 - val_loss: 0.3505 - val_accuracy: 0.8556\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8728 - val_loss: 0.3500 - val_accuracy: 0.8512\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8742 - val_loss: 0.3504 - val_accuracy: 0.8525\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8714 - val_loss: 0.3520 - val_accuracy: 0.8556\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8731 - val_loss: 0.3499 - val_accuracy: 0.8550\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8736 - val_loss: 0.3513 - val_accuracy: 0.8550\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8714 - val_loss: 0.3511 - val_accuracy: 0.8544\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8714 - val_loss: 0.3516 - val_accuracy: 0.8512\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8722 - val_loss: 0.3526 - val_accuracy: 0.8525\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8728 - val_loss: 0.3509 - val_accuracy: 0.8581\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8717 - val_loss: 0.3519 - val_accuracy: 0.8537\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8750 - val_loss: 0.3543 - val_accuracy: 0.8537\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3058 - accuracy: 0.8742 - val_loss: 0.3521 - val_accuracy: 0.8556\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8706 - val_loss: 0.3523 - val_accuracy: 0.8537\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8752 - val_loss: 0.3522 - val_accuracy: 0.8519\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8745 - val_loss: 0.3518 - val_accuracy: 0.8544\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8722 - val_loss: 0.3564 - val_accuracy: 0.8575\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8747 - val_loss: 0.3534 - val_accuracy: 0.8562\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8722 - val_loss: 0.3543 - val_accuracy: 0.8506\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8719 - val_loss: 0.3544 - val_accuracy: 0.8519\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8722 - val_loss: 0.3550 - val_accuracy: 0.8531\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8739 - val_loss: 0.3543 - val_accuracy: 0.8544\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8737 - val_loss: 0.3546 - val_accuracy: 0.8581\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8737 - val_loss: 0.3566 - val_accuracy: 0.8506\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8714 - val_loss: 0.3572 - val_accuracy: 0.8506\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8728 - val_loss: 0.3552 - val_accuracy: 0.8550\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8736 - val_loss: 0.3551 - val_accuracy: 0.8500\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8727 - val_loss: 0.3548 - val_accuracy: 0.8556\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8758 - val_loss: 0.3572 - val_accuracy: 0.8531\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8756 - val_loss: 0.3569 - val_accuracy: 0.8531\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8763 - val_loss: 0.3564 - val_accuracy: 0.8550\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8753 - val_loss: 0.3597 - val_accuracy: 0.8562\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8730 - val_loss: 0.3562 - val_accuracy: 0.8556\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8745 - val_loss: 0.3561 - val_accuracy: 0.8556\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8734 - val_loss: 0.3571 - val_accuracy: 0.8525\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8766 - val_loss: 0.3567 - val_accuracy: 0.8587\n"
     ]
    }
   ],
   "source": [
    "history_=[]\n",
    "for model in models:\n",
    "    model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "    history=model.fit(x_train_scaled,y_train,epochs=100,validation_split=0.2)\n",
    "    history_.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efbf5203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:59:27.713742Z",
     "iopub.status.busy": "2022-10-19T05:59:27.713273Z",
     "iopub.status.idle": "2022-10-19T05:59:27.727668Z",
     "shell.execute_reply": "2022-10-19T05:59:27.726419Z"
    },
    "papermill": {
     "duration": 1.068693,
     "end_time": "2022-10-19T05:59:27.730277",
     "exception": false,
     "start_time": "2022-10-19T05:59:26.661584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.1860194 ,  0.18090005, -0.27540964, -0.16389112,  0.03227858,\n",
       "          0.26651865,  0.53569657,  0.2603735 , -0.25308546, -0.2613331 ,\n",
       "         -0.40113768, -0.07377212, -0.59485865, -0.19798252,  0.07256249,\n",
       "          0.16273254,  0.24759588, -0.22710381,  0.3324152 ],\n",
       "        [ 0.31220454,  0.0893738 ,  0.3530643 ,  0.18439719,  0.39415762,\n",
       "          0.00916569,  0.47833744, -0.29405412, -0.07778591, -0.37057573,\n",
       "         -0.5673477 , -0.38279226, -0.09282178, -0.20099093,  0.24825935,\n",
       "          0.57362854, -0.98986447, -0.05338891,  0.1911412 ],\n",
       "        [ 0.52295244,  0.01016274, -0.46637705, -0.04173085,  0.15553786,\n",
       "         -0.6200961 , -0.23179474, -0.4927396 , -1.096798  ,  0.17186452,\n",
       "         -0.06423361,  0.10471961,  0.1793056 , -0.2254294 ,  0.46895504,\n",
       "          0.34788164, -1.5894063 ,  0.028808  ,  0.16821812],\n",
       "        [-0.40859404,  0.46238017,  0.20631044,  0.00474041,  0.44559   ,\n",
       "         -0.1645321 , -0.33244953,  0.18157984, -0.37705392,  0.28227177,\n",
       "          0.00682232, -0.54719067, -0.0095417 , -0.4203646 ,  0.2948542 ,\n",
       "          0.10069239, -0.6888005 , -0.39319333,  0.49568775],\n",
       "        [-0.249978  , -0.32389277, -0.1723581 , -0.05831233,  0.36151126,\n",
       "         -0.48557815,  0.1161778 ,  0.08228688,  0.06856909, -0.38428605,\n",
       "         -0.185647  , -0.26086244,  0.45920035, -0.10791251, -0.19087829,\n",
       "          0.56384206,  0.23670658, -0.06281652, -0.7760562 ],\n",
       "        [-0.2500193 , -0.04975462,  0.44708902,  0.24981137, -0.46284744,\n",
       "          0.00188301, -0.24413706, -0.11881419,  0.30563274, -0.43697694,\n",
       "          0.45120773, -0.04621331,  0.4680408 ,  0.44070953,  0.04307644,\n",
       "         -0.08483399, -0.78312856,  0.4008602 ,  0.03885634],\n",
       "        [ 0.31464377, -0.01548283, -1.0153774 ,  0.36707103,  0.41849273,\n",
       "          0.08887764,  0.6619842 ,  0.539815  , -0.4813597 , -0.00229338,\n",
       "         -0.23749219, -0.33295706,  0.31559792, -0.07644683,  0.4644035 ,\n",
       "          0.36161214, -0.5128228 ,  0.8535335 ,  0.24316826],\n",
       "        [-0.8877709 ,  0.21292213,  0.37554196, -0.635038  , -0.48888955,\n",
       "          0.04468231, -0.16828857, -0.21292318, -0.1419657 , -0.15074444,\n",
       "          0.3393    , -1.1241174 , -0.24458085,  0.49333772, -0.06521157,\n",
       "          0.01541745, -0.24211213, -0.07696513, -0.21913281],\n",
       "        [ 0.11493208,  0.15605183, -0.36422554,  0.02635931,  0.46332505,\n",
       "         -0.5580019 ,  0.15863156, -0.23383127, -0.28305435, -0.05059097,\n",
       "         -0.21398629,  0.48995778, -0.01291818,  0.11714718, -0.47399658,\n",
       "          0.16221546, -0.24720801,  0.39820698, -0.80689365],\n",
       "        [ 0.3535783 ,  0.45718616, -0.11423188,  0.3213775 , -0.2947345 ,\n",
       "         -0.3353234 ,  0.25480652,  0.03437891, -0.3205357 , -0.0293973 ,\n",
       "         -0.06721413,  0.41045716, -0.04132653, -0.39709276, -0.1735674 ,\n",
       "         -0.0492083 , -0.29130793,  0.1479848 , -0.99429774],\n",
       "        [-1.1209604 , -0.3889701 ,  0.22042981,  0.04267294,  0.14426568,\n",
       "          0.2281137 , -0.20774987,  0.17228745,  0.5451157 , -0.39207324,\n",
       "          0.21763486,  0.05695188,  0.5699474 ,  0.64156324,  0.07923763,\n",
       "         -0.0499012 ,  0.23040162,  0.48488656,  0.46909964],\n",
       "        [-0.13014132, -0.3794124 , -0.1338359 , -0.24143095,  0.12254418,\n",
       "         -0.8118649 ,  0.4904972 , -0.10813469,  0.42426297,  0.00305032,\n",
       "         -0.10729375,  0.5460515 ,  0.06743635, -0.4723334 , -0.27939463,\n",
       "          0.40032697,  0.49865317,  0.6755877 , -1.0978699 ],\n",
       "        [-0.9737153 , -0.5220785 ,  0.15721206,  0.55880594, -1.0024772 ,\n",
       "          0.08734848, -0.05349527,  0.41452828,  0.24048242, -0.06499226,\n",
       "          0.47389558, -0.3786119 , -0.08405262,  0.5780692 , -0.6297427 ,\n",
       "          0.613427  , -0.69694686,  0.34095478,  0.18029547],\n",
       "        [-0.83505243, -0.15566991, -0.7819325 ,  0.3625615 , -0.1316857 ,\n",
       "          0.08937572,  0.27926388, -0.02810165,  0.57368463, -0.2745446 ,\n",
       "          0.4393064 , -0.44038707,  0.07578523, -0.48436302,  0.03365334,\n",
       "         -0.08864933, -0.07276069,  0.04030164, -0.6929895 ],\n",
       "        [ 0.05273455,  0.30414376, -0.011515  ,  0.38046324,  0.05863789,\n",
       "         -0.16792385,  0.14087582, -0.6576929 ,  0.2478488 ,  0.08411663,\n",
       "          0.65300333, -0.7179855 , -0.25417385,  0.48009127,  0.19240323,\n",
       "         -0.09662029,  0.42239892,  0.27306718, -0.01696934],\n",
       "        [-0.06612185,  0.09900952, -0.17627275,  0.47147515, -0.1289878 ,\n",
       "         -0.4005107 ,  0.02343098,  0.25408953,  0.07991157, -0.37454566,\n",
       "         -0.17255402,  0.04121722,  0.36121935, -0.5406843 , -0.3683563 ,\n",
       "          0.42305186,  0.5973859 ,  0.03794596, -0.80022234],\n",
       "        [ 0.5951664 ,  0.19460544,  0.43877184,  0.10141414, -0.34770718,\n",
       "          0.0613114 , -0.00710298, -0.71537775, -0.07903876,  0.21273161,\n",
       "         -0.23552778,  0.15563382,  0.599755  , -0.30249432,  0.0504192 ,\n",
       "          0.2828298 , -0.37520075,  0.38994592, -0.18529923],\n",
       "        [-0.5722277 ,  0.26115125,  0.05205844, -0.4148933 ,  0.13410695,\n",
       "          0.35941064, -0.24062067,  0.27873674,  0.31075215, -0.12088202,\n",
       "         -0.36911094, -0.6424235 ,  0.16355366, -0.5139446 ,  0.43349475,\n",
       "          0.1464824 , -0.2870145 , -0.4256314 ,  0.3776745 ],\n",
       "        [ 0.36353058,  0.23362863,  0.47252098, -0.3146315 ,  0.0859893 ,\n",
       "          0.8622804 ,  0.18881382,  0.11532792, -0.50774443, -0.2938481 ,\n",
       "         -0.4616876 , -0.08621575, -0.15659769, -0.36366445,  0.47580048,\n",
       "          0.00793184, -0.86329836,  0.2261654 ,  0.46141505]],\n",
       "       dtype=float32),\n",
       " array([-0.07177538, -0.03024991,  0.09109331,  0.19016501,  0.06829351,\n",
       "         0.21154726,  0.1596048 ,  0.05643465, -0.16684063, -0.10795616,\n",
       "        -0.11114848, -0.10705449,  0.28803468, -0.2974829 ,  0.19761999,\n",
       "         0.24456504, -0.17710915,  0.22750424,  0.39248574], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0388db56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:59:30.022711Z",
     "iopub.status.busy": "2022-10-19T05:59:30.021779Z",
     "iopub.status.idle": "2022-10-19T05:59:30.033856Z",
     "shell.execute_reply": "2022-10-19T05:59:30.032649Z"
    },
    "papermill": {
     "duration": 1.163496,
     "end_time": "2022-10-19T05:59:30.036330",
     "exception": false,
     "start_time": "2022-10-19T05:59:28.872834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6187649965286255,\n",
       "  0.5306609869003296,\n",
       "  0.49669140577316284,\n",
       "  0.48553135991096497,\n",
       "  0.479203999042511,\n",
       "  0.4739445149898529,\n",
       "  0.4689542353153229,\n",
       "  0.4639718234539032,\n",
       "  0.45875614881515503,\n",
       "  0.4537186026573181,\n",
       "  0.4490748345851898,\n",
       "  0.4452650845050812,\n",
       "  0.44209420680999756,\n",
       "  0.43982037901878357,\n",
       "  0.4376543462276459,\n",
       "  0.4364529848098755,\n",
       "  0.43552714586257935,\n",
       "  0.4349309206008911,\n",
       "  0.43445995450019836,\n",
       "  0.43422040343284607,\n",
       "  0.43383488059043884,\n",
       "  0.4335479736328125,\n",
       "  0.43350863456726074,\n",
       "  0.43326979875564575,\n",
       "  0.43317973613739014,\n",
       "  0.43314337730407715,\n",
       "  0.43295735120773315,\n",
       "  0.43299856781959534,\n",
       "  0.4329577684402466,\n",
       "  0.4328817129135132,\n",
       "  0.43281444907188416,\n",
       "  0.43275532126426697,\n",
       "  0.4327675998210907,\n",
       "  0.4327813684940338,\n",
       "  0.4327450096607208,\n",
       "  0.43275710940361023,\n",
       "  0.43267613649368286,\n",
       "  0.4327663481235504,\n",
       "  0.43261444568634033,\n",
       "  0.4326590597629547,\n",
       "  0.4327549636363983,\n",
       "  0.4326659142971039,\n",
       "  0.4327479600906372,\n",
       "  0.43272674083709717,\n",
       "  0.4327482283115387,\n",
       "  0.432649701833725,\n",
       "  0.43264836072921753,\n",
       "  0.432617723941803,\n",
       "  0.4326731860637665,\n",
       "  0.4327267110347748,\n",
       "  0.43259167671203613,\n",
       "  0.4326823055744171,\n",
       "  0.4326961040496826,\n",
       "  0.4326794743537903,\n",
       "  0.4326556324958801,\n",
       "  0.43267858028411865,\n",
       "  0.4326251149177551,\n",
       "  0.4326048195362091,\n",
       "  0.4326847791671753,\n",
       "  0.4326395094394684,\n",
       "  0.4325626790523529,\n",
       "  0.43284711241722107,\n",
       "  0.43266966938972473,\n",
       "  0.43266555666923523,\n",
       "  0.4327629804611206,\n",
       "  0.43266838788986206,\n",
       "  0.4325573742389679,\n",
       "  0.43277305364608765,\n",
       "  0.4325871765613556,\n",
       "  0.43260300159454346,\n",
       "  0.432754248380661,\n",
       "  0.4326082468032837,\n",
       "  0.43272656202316284,\n",
       "  0.4326264560222626,\n",
       "  0.43265727162361145,\n",
       "  0.4325564205646515,\n",
       "  0.43264755606651306,\n",
       "  0.4326281249523163,\n",
       "  0.4327256679534912,\n",
       "  0.4326486587524414,\n",
       "  0.43268874287605286,\n",
       "  0.4326866865158081,\n",
       "  0.43259644508361816,\n",
       "  0.4326131343841553,\n",
       "  0.43259677290916443,\n",
       "  0.4325328767299652,\n",
       "  0.432574987411499,\n",
       "  0.4327034652233124,\n",
       "  0.4326377511024475,\n",
       "  0.43267035484313965,\n",
       "  0.43262171745300293,\n",
       "  0.4328381419181824,\n",
       "  0.4325866997241974,\n",
       "  0.43261778354644775,\n",
       "  0.43276160955429077,\n",
       "  0.43261075019836426,\n",
       "  0.43266069889068604,\n",
       "  0.4326595664024353,\n",
       "  0.43264615535736084,\n",
       "  0.43262341618537903],\n",
       " 'accuracy': [0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7945312261581421,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7928125262260437,\n",
       "  0.7920312285423279,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7925000190734863,\n",
       "  0.7934374809265137,\n",
       "  0.792187511920929,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7914062738418579,\n",
       "  0.7917187213897705,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7915624976158142,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7918750047683716,\n",
       "  0.7942187786102295,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137],\n",
       " 'val_loss': [0.559866726398468,\n",
       "  0.49697890877723694,\n",
       "  0.47785624861717224,\n",
       "  0.4696589708328247,\n",
       "  0.46387702226638794,\n",
       "  0.45935457944869995,\n",
       "  0.45482581853866577,\n",
       "  0.4503244459629059,\n",
       "  0.44568127393722534,\n",
       "  0.4410693347454071,\n",
       "  0.4371178448200226,\n",
       "  0.434187650680542,\n",
       "  0.43187716603279114,\n",
       "  0.42997732758522034,\n",
       "  0.42850053310394287,\n",
       "  0.42753154039382935,\n",
       "  0.42678481340408325,\n",
       "  0.42655429244041443,\n",
       "  0.42636507749557495,\n",
       "  0.42613929510116577,\n",
       "  0.42588111758232117,\n",
       "  0.42569583654403687,\n",
       "  0.4254947900772095,\n",
       "  0.42523303627967834,\n",
       "  0.42508769035339355,\n",
       "  0.42479172348976135,\n",
       "  0.42474880814552307,\n",
       "  0.4245489537715912,\n",
       "  0.42437171936035156,\n",
       "  0.4243597686290741,\n",
       "  0.4244692921638489,\n",
       "  0.4240688383579254,\n",
       "  0.4239719808101654,\n",
       "  0.4238710105419159,\n",
       "  0.42383137345314026,\n",
       "  0.42379382252693176,\n",
       "  0.42380669713020325,\n",
       "  0.42370644211769104,\n",
       "  0.4237276017665863,\n",
       "  0.42361557483673096,\n",
       "  0.42357856035232544,\n",
       "  0.42347514629364014,\n",
       "  0.4234583377838135,\n",
       "  0.42353111505508423,\n",
       "  0.42345941066741943,\n",
       "  0.42343512177467346,\n",
       "  0.42351436614990234,\n",
       "  0.4234315752983093,\n",
       "  0.42339766025543213,\n",
       "  0.42349299788475037,\n",
       "  0.42347607016563416,\n",
       "  0.4234946370124817,\n",
       "  0.4234440326690674,\n",
       "  0.4235207736492157,\n",
       "  0.42345044016838074,\n",
       "  0.42342594265937805,\n",
       "  0.4234012961387634,\n",
       "  0.42343029379844666,\n",
       "  0.42341122031211853,\n",
       "  0.4233856499195099,\n",
       "  0.42348384857177734,\n",
       "  0.4234095811843872,\n",
       "  0.42346450686454773,\n",
       "  0.4234454333782196,\n",
       "  0.4234875738620758,\n",
       "  0.4235056936740875,\n",
       "  0.42346659302711487,\n",
       "  0.42340144515037537,\n",
       "  0.4234219789505005,\n",
       "  0.4233294427394867,\n",
       "  0.42341744899749756,\n",
       "  0.42332184314727783,\n",
       "  0.42324867844581604,\n",
       "  0.42327967286109924,\n",
       "  0.42327749729156494,\n",
       "  0.4233555197715759,\n",
       "  0.42343100905418396,\n",
       "  0.42331141233444214,\n",
       "  0.42326000332832336,\n",
       "  0.4233010411262512,\n",
       "  0.42334869503974915,\n",
       "  0.4233056604862213,\n",
       "  0.4232311248779297,\n",
       "  0.42325088381767273,\n",
       "  0.42340224981307983,\n",
       "  0.4232579171657562,\n",
       "  0.4233993589878082,\n",
       "  0.4233607351779938,\n",
       "  0.4233180582523346,\n",
       "  0.4233037233352661,\n",
       "  0.4234117865562439,\n",
       "  0.42331424355506897,\n",
       "  0.4233590364456177,\n",
       "  0.4233415722846985,\n",
       "  0.4232357144355774,\n",
       "  0.4232989549636841,\n",
       "  0.42320847511291504,\n",
       "  0.4232725203037262,\n",
       "  0.42332085967063904,\n",
       "  0.4234353005886078],\n",
       " 'val_accuracy': [0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_[0].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1094e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:25:02.461738Z",
     "iopub.status.busy": "2022-10-19T05:25:02.461361Z",
     "iopub.status.idle": "2022-10-19T05:25:02.468682Z",
     "shell.execute_reply": "2022-10-19T05:25:02.467601Z",
     "shell.execute_reply.started": "2022-10-19T05:25:02.461706Z"
    },
    "papermill": {
     "duration": 1.174493,
     "end_time": "2022-10-19T05:59:32.249486",
     "exception": false,
     "start_time": "2022-10-19T05:59:31.074993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53a33970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:59:34.447325Z",
     "iopub.status.busy": "2022-10-19T05:59:34.446799Z",
     "iopub.status.idle": "2022-10-19T05:59:34.454423Z",
     "shell.execute_reply": "2022-10-19T05:59:34.453029Z"
    },
    "papermill": {
     "duration": 1.166656,
     "end_time": "2022-10-19T05:59:34.456811",
     "exception": false,
     "start_time": "2022-10-19T05:59:33.290155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score  0.7945312261581421\n",
      "best score  0.8462499976158142\n",
      "best score  0.8587499856948853\n",
      "best score  0.8634374737739563\n",
      "best score  0.8389062285423279\n",
      "best score  0.8626562356948853\n",
      "best score  0.8650000095367432\n",
      "best score  0.8701562285423279\n",
      "best score  0.870312511920929\n",
      "best score  0.8684375286102295\n",
      "best score  0.8695312738418579\n",
      "best score  0.8671875\n",
      "best score  0.8717187643051147\n",
      "best score  0.8717187643051147\n",
      "best score  0.8704687356948853\n",
      "best score  0.8693749904632568\n",
      "best score  0.875\n",
      "best score  0.8734375238418579\n",
      "best score  0.8765624761581421\n"
     ]
    }
   ],
   "source": [
    "for history in history_:\n",
    "    best_score = max(history.history['accuracy'])\n",
    "    print(\"best score \",best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b043b067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:59:36.712754Z",
     "iopub.status.busy": "2022-10-19T05:59:36.711920Z",
     "iopub.status.idle": "2022-10-19T05:59:36.718379Z",
     "shell.execute_reply": "2022-10-19T05:59:36.717217Z"
    },
    "papermill": {
     "duration": 1.06954,
     "end_time": "2022-10-19T05:59:36.720811",
     "exception": false,
     "start_time": "2022-10-19T05:59:35.651271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score val score 0.7987499833106995\n",
      "best score val score 0.8493750095367432\n",
      "best score val score 0.8550000190734863\n",
      "best score val score 0.8637499809265137\n",
      "best score val score 0.8387500047683716\n",
      "best score val score 0.856249988079071\n",
      "best score val score 0.8600000143051147\n",
      "best score val score 0.8606250286102295\n",
      "best score val score 0.8600000143051147\n",
      "best score val score 0.8612499833106995\n",
      "best score val score 0.8668749928474426\n",
      "best score val score 0.8631250262260437\n",
      "best score val score 0.8631250262260437\n",
      "best score val score 0.8600000143051147\n",
      "best score val score 0.859375\n",
      "best score val score 0.8600000143051147\n",
      "best score val score 0.8600000143051147\n",
      "best score val score 0.8643749952316284\n",
      "best score val score 0.8600000143051147\n"
     ]
    }
   ],
   "source": [
    "for history in history_:\n",
    "    best_score = max(history.history['val_accuracy'])\n",
    "    print(\"best score val score\",best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "944d05e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:59:39.021610Z",
     "iopub.status.busy": "2022-10-19T05:59:39.020851Z",
     "iopub.status.idle": "2022-10-19T05:59:39.341147Z",
     "shell.execute_reply": "2022-10-19T05:59:39.340306Z"
    },
    "papermill": {
     "duration": 1.462105,
     "end_time": "2022-10-19T05:59:39.344255",
     "exception": false,
     "start_time": "2022-10-19T05:59:37.882150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_[18].history['loss'])\n",
    "plt.plot(history_[18].history['val_loss'])\n",
    "plt.title('Loss PLOT')\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('error')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_[18].history['accuracy'])\n",
    "plt.plot(history_[18].history['val_accuracy'])\n",
    "plt.title('Accuracy PLOT')\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "167dbf27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T05:59:41.561138Z",
     "iopub.status.busy": "2022-10-19T05:59:41.560442Z",
     "iopub.status.idle": "2022-10-19T05:59:43.218823Z",
     "shell.execute_reply": "2022-10-19T05:59:43.217378Z"
    },
    "papermill": {
     "duration": 2.824302,
     "end_time": "2022-10-19T05:59:43.221428",
     "exception": false,
     "start_time": "2022-10-19T05:59:40.397126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 19 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i=1\n",
    "for history in history_:\n",
    "    plt.subplot(5,4,i)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f5505",
   "metadata": {
    "papermill": {
     "duration": 1.147379,
     "end_time": "2022-10-19T05:59:45.508064",
     "exception": false,
     "start_time": "2022-10-19T05:59:44.360685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 947.489537,
   "end_time": "2022-10-19T05:59:50.045000",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-19T05:44:02.555463",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
